<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Hybrid Physical-Deep Learning Models for<br> Astronomical Inverse Problems</title>

		<meta name="description" content="Blending WG Update Feb. 2020">
		<meta name="author" content="Francois Lanusse">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<link rel="stylesheet" href="reveal.js/css/reset.css">
		<link rel="stylesheet" href="reveal.js/css/reveal.css">
		<link rel="stylesheet" href="reveal.js/css/theme/darkenergy.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="reveal.js/lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

        <section data-background-image="/assets/lsst_stills_0009_crop.jpg" >
            <div class="container">
              <div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
                <h2>Hybrid Physical-Deep Learning Models for Astronomical Inverse Problems</h2>
                <h3><a href="https://arxiv.org/abs/1912.03980"> arXiv:1912.03980</a> </h3>
            </div>
          </div>
          <hr>
          <div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0);">
            <h3>Fran√ßois Lanusse,<br> in collaboration wih Peter Melchior, Fred Moolekamp, Remy Joseph </h3>
              <div class="container" >
                  <div class="col">
                    <div align="left" style="margin-left: 20px;">
                    <br>
                    <br>

                    <img src="/assets/CosmoStatDarkBK.png" class="plain" height="80"></img>
                    <br>
                    </div>
                  </div>

                  <div class="col">
                    <br>
                    <br>
                    <img src="/assets/logo_cnrs.png" class="plain" height="150"></img>
                  </div>

                  <div class="col">
                    <img src="/assets/desc-logo-inv.png" class="plain" height="200"></img>

                  </div>
                </div>
            </div>
          </section>

      <section>
      <section data-background="/assets/gal_hsc.png">

      </section>
 				<section>
 					<h3 class="slide-title">The challenge of galaxy blending</h3>
							<div class="container">
									<div class="col">
										<div style="position:relative; width:480px; height:500px; margin:0 auto;">
											<img class="fragment current-visible plain"  data-src="/assets/hsc_deblending_success.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
											<img class="fragment plain" data-src="/assets/hsc_shredded.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
										</div>
										<div class="fragment" data-fragment-index="0" style="float:left; font-size: 20px">Bosch et al. 2017</div>
									</div>
									<div class="col">
									<ul>
										<li class="fragment fade-up" data-fragment-index="0"> In HSC over 60% of all galaxies are blended</li>
										<br>
										<li class="fragment fade-up" data-fragment-index="0"> Important impact on our main cosmological probes</li>
										<br>
										<li class="fragment fade-up" data-fragment-index="1"> Current generation of deblenders does not meet our target requirements</li>
										<br>
										<ul class="fragment fade-up" data-fragment-index="2">
											<li> Existing methods rely on simple assumptions about galaxy profiles, like <i>symmetry</i> or <i>monotonicity</i></li>
										</ul>
									</ul>
									</div>
							</div>

							<div class="fragment fade-up"data-fragment-index="3" >
								Deblending is an ill-posed inverse problem, akin to <i>Blind Source Separation</i>. The is no <b>single solution</b>.<br>
								$\Longrightarrow$ Intuitively, the key will to leverage an understanding of how individual <i>galaxies look like</i>.
							</div>
 				</section>
				</section>

					<section>
					<h3 class="slide-title">Deep Learning applied to deblending (Reiman & Gohre 2018)</h3>
								<div>
								<img class="plain" data-src="/assets/Reiman2018_1.png" />
									Branched GAN model for deblending
								</div>

							<div class="block fragment">
								<div class="block-title">
									The issue with <i>black-box</i> models
								</div>
								<div class="block-content">
									<ul>
										<li> No explicit control of noise, PSF, depth, number of sources.
												<ul>
													<li> Model would have to be retrained for all observing configurations
													</li>
												</ul>
										</li>
										<br>
										<li> No guarantees on the network output (e.g. flux preservation, artifacts)
										</li>
									</ul>
							</div>
						</div>
					</section>


				<section>
				<section>
					<h3 class="slide-title">Linear inverse problems</h3>

					$\boxed{y =  \mathbf{A}x + n}$
					<br>
					<br>
					$\mathbf{A}$ is known and encodes our physical understanding of the problem.
					<span class="fragment"><br>$\Longrightarrow$ When non-invertible or ill-conditioned, the inverse problem is ill-posed with no unique solution $x$</span>
					<div class="container fragment fade-up">
							<div class="col">
								<img data-src="/assets/pluto_smooth.png" class="plain"></img>
								Deconvolution
							</div>
							<div class="col">
								<img data-src="/assets/pluto_missing.png" class="plain"></img>
								Inpainting
							</div>
							<div class="col">
								<img data-src="/assets/plutoNoise.png" class="plain"></img>
								Denoising
							</div>
					</div>

				</section>

				<section data-vertical-align-top>
					$\boxed{y =  \mathbf{A}x + n}$
					<br>
					<br>
					The Bayesian view of the problem:
					<br>
					<br>
					$$ p(x | y) \propto p(y | x) \ p(x) $$
					<br>

					<ul>
						<li class="fragment fade-up">$p(y | x)$ is the data likelihood, which <b>contains the physics</b><br>
						</li>
						<br>
						<li class="fragment fade-up">$p(x)$ is our prior knowledge on the solution.</li>
					</ul>
					<br>
					<br>
					<div class="fragment fade-up">
					With these concepts in hand, we want to estimate the Maximum A Posteriori solution:
					<br>
					<br>
					$$\hat{x} = \arg\max\limits_x \ \log p(y \ | \ x)  + \log p(x)$$
					<br>
					For instance, if $n$ is Gaussian, $\hat{x} = \arg\max\limits_x \ \frac{1}{2} \parallel y - \mathbf{A} x \parallel_{\mathbf{\Sigma}}^2 + \log p(x)$
					</div>
					<br>
					<div class="fragment fade-up">
						<h3>How do you choose the prior ?</h3>
					</div>
				</section>

				<section>
					<h3 class="slide-title"> Classical examples of signal priors </h3>
						<div class="container">
							<div class="col">
								Sparse
								<img data-src="/assets/wavelet.png" height="400" class="plain"></img><br>
								$$ \log p(x) = \parallel \mathbf{W} x \parallel_1 $$
							</div>
							<div class="col">
								Gaussian
								<img data-src="/assets/zknj8.jpg" height="400" class="plain"></img>
								$$ \log p(x) = x^t \mathbf{\Sigma^{-1}} x $$
							</div>
							<div class="col">
								Total Variation
								<img data-src="/assets/shepp-Logan.ppm" class="plain"></img>
								$$ \log p(x) = \parallel \nabla x \parallel_1 $$

							</div>
					</div>
				</section>

				<section data-background="/assets/hsc_screen.png">
						<h2>But what about this?</h2>

				</section>
			</section>

			<section class="inverted" data-background="#000">
				<h2>
				Can we use Deep Learning to learn the prior from data?</h2>
			</section>

			<section>
				<h3 class="slide-title" >A deblending toy example</h3>
				<div class="container">
				<div class="col">
						<div class="fig-container" data-file="dgm_prior.html" data-style="height: 550px;"></div>
						<br>
						Try me out at: <a href="https://eiffl.github.io/DeepPriors">https://eiffl.github.io/DeepPriors</a>
				</div>

			 <div class="col">
				 <ul>
					 <li>Assume a blend with two components $x_1$ and $x_2$ <br> $x_1 + x_2$ must match the data $y$</li>
					 <br>
					 <li>Each component of the blend should lie on the "realistic galaxy manifold", symbolized by the two-moons distribution.</li>
				 </ul>
				 <p> We are solving: </p>
					 $\arg \max - \frac{1}{2} \parallel {\color{Orchid} y} - {\color{red} \sum_{\color{red} i} {\color{red} x}_{\color{red} i}} \parallel_2^2 + \log p({\color{SkyBlue} x_{\color{SkyBlue} 1}}) + \log p({\color{GreenYellow} x_{\color{GreenYellow} 2}}) $
					 <br>
					 <br>
					 This can be done by gradient descent as long  as one has access to $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d \color{orange}x}$.
		 	 </div>
	 </div>
		</section>
			<section data-vertical-align-top>
				<h3 class="slide-title" >Not all generative models are created equal</h3>
							<img data-src="/assets/generative_models_table.png" class="plain"></img>
		 						<div style="float:right; font-size: 20px">Grathwohl et al. 2018</div>
					<br>
					<br>
				<ul>
					<li> GANs and VAEs are very common and successfull but do not fit our purposes.</li>
					<br>
					<li> We need a model which can provide explicitly $\log p(x)$.</li>
					<br>
				</ul>
			</section>

			<section>
				<h3  class="slide-title">PixelCNN: Likelihood-based Autoregressive generative model</h3>
				<div class="container">
				<div class="col">
						Models the probability $p(x)$ of an image $x$ as:
						$$ p_{\theta}(x) = \prod_{i=0}^{n} p_{\theta}(x_i | x_{i-1} \ldots x_0) $$
						<ul>
								<li>Some of the best log-likelihoods on the market.</li>
								<li>Extremely stable during training.</li>
								<li>Slow to sample from.</li>
						</ul>
						<br>
						<br>

						<div class="fragment fade-up">
							<img data-src="/assets/speedup.gif" class="plain"></img>
							<br>
			 				<div style="float:left; font-size: 20px">Ramachandran et al. 2017</div>
						</div>

				</div>

				<div class="col">
						<img data-src="/assets/pixel_cnn_conv.png" class="plain"></img>
		 				<div style="float:right; font-size: 20px">van den Oord et al. 2016</div>
				</div>
			 </div>
			</section>

			<section>
				<h3 class="slide-title"> The Scarlet algorithm: deblending as an optimization problem</h3>
						<div style="float:right; font-size: 20px">Melchior et al. 2018</div>

						$$ \mathcal{L} = \frac{1}{2} \parallel \mathbf{\Sigma}^{-1/2} (\ Y - P \ast A S \ ) \parallel_2^2 - \sum_{i=1}^K \log p_{\theta}(S_i) + \sum_{i=1}^K g_i(A_i) +  \sum_{i=1}^K f_i(S_i)$$

				<div class="container">
				<div class="col">
						<img data-src="/assets/scarlet_data.png" height=450 class="plain"></img>
				</div>

				<div class="col">

					Where for a $K$ component blend:
					<br>
						<ul>
						<li>$P$ is the convolution with the instrumental response</li>
						<br>
						<li>$A_i$ are channel-wise galaxy SEDs, $S_i$ are the morphology models</li>
						<br>
						<li>$\mathbf{\Sigma}$ is the noise covariance</li>
						<br>
						<li>$\log p_\theta$ is a PixelCNN prior</li>
						<br>
						<li>$f_i$ and $g_i$ are arbitrary additional non-smooth consraints, e.g. positivity, monotonicity...</li>
						</ul>
				</div>
			</div>

			<span class="fragment fade-up">$\Longrightarrow$ Explicit physical modeling of the observed sky</span>
			</section>

			 <section>
				<h3  class="slide-title">Training the morphology prior</h3>

				<div class="container">
					<div class="col">
						<img data-src="/assets/cosmos_training.png" height=450 class="plain"></img>
						<div> Postage stamps of isolated COSMOS galaxies used for training, at WFIRST resolution and fixed fiducial PSF</div>
				</div>

				<div class="col">
				<div class="container fragment fade-in">
					<div class="col">
						isolated galaxy
					<img data-src="/assets/gal_1.png" class="plain"></img>
					<span> $\log p_\theta(x) = 3293.7$ </span>
				</div>

					<div class="col">
						artificial blend
					<img data-src="/assets/gal_2.png" class="plain"></img>
					<span> $\log p_\theta(x) = 3100.5 $ </span>
				</div>
					</div>
				</div>
			</section>

			<section>
				<section>
				<h3 class="slide-title">Scarlet in action</h3>

				<div class="container">
					<div class="col">
						Input blend
					<div style="position:relative; width:480px; height:480px; margin:0 auto;">
					<img data-src="/assets/scar_input.png" class="plain"></img>
				</div>
					</div>

				<div class="col">
					<span class="fragment" data-fragment-index="0">Solution</span>
					<div style="position:relative; width:480px; height:480px; margin:0 auto;">
							  <img class="fragment current-visible plain" data-src="/assets/old_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
							  <img class="fragment  plain" data-src="/assets/pix_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
					</div>
				</div>

				<div class="col">
					<span class="fragment" data-fragment-index="0">Residuals</span>
					<div style="position:relative; width:480px; height:480px; margin:0 auto;">
							  <img class="fragment current-visible plain" data-src="/assets/old_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
							  <img class="fragment  plain" data-src="/assets/pix_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
					</div>
				</div>
				</div>

				<ul>
						<li class="fragment fade-up" data-fragment-index="0">Classic priors (monotonicity, symmetry).</li>
						<br>

						<li class="fragment fade-up" data-fragment-index="1">Deep Morphology prior.</li>
				</ul>

			</section>
			<section>
				<div class="container">
					<div class="col">
						True Galaxy
					<img data-src="/assets/true_input.png" class="plain"></img>
				</div>

				<div class="col">
					Deep Morphology Prior Solution

								<img class=" plain" data-src="/assets/pix_rec2.png"  />

				</div>

				<div class="col">
					Monotonicity + Symmetry Solution
								<img class=" plain" data-src="/assets/scar_rec2.png" />
					</div>
				</div>
			</section>
			</section>


      <section>
				<h3 class="slide-title"> Extending to multi-band images</h3>

						<img class=" plain" data-src="/assets/scarlet_hsc.png" />

      </section>


			<section>
				<h3 class="slide-title"> Takeaway message</h3>

				<br>

        <ul>
          <li> We have introduce an <b class="alert">hybrid physical/deep learning model for inverse problems</b>
            <ul>
              <br>
              <li class="fragment"> Incorporate prior astrophysical knowledge as a data-driven prior
              </li>
              <br>

              <li class="fragment"> Interpretable in terms of physical components of the astronomical scene
              </li>
              <br>

              <li class="fragment"> Can accomodate different observing conditions and instruments
                <br> $\Longrightarrow$ For instance, for the joint modeling of  LSST/Euclid data
              </li>
            </ul>
          </li>

          <br>
          <br>

          <li class="fragment"> We are now in the process of evaluating the benefits of the approach compared to standard scarlet.
            Some potential complications:
            <ul>
              <li> Accounting for color gradients in this new model
              </li>
              <br>
              <li> Evaluating prior-induced biases on lensing related quantities.
              </li>
            </ul>


          </li>

        </ul>

			</section>



      				<section>
      					<h1> Conclusion </h1>
      				</section>


      						<section>
      							<h3 class="slide-title"> Conclusion </h3>

      													<div class="block ">
      														<div class="block-title">
                                    How can Deep Generative Models help us make sense of increasingly complex images ?
      														</div>
      														<div class="block-content">
                                    <br>
      															<ul>
      																<li class="fragment"> Produce more <b>realistic image simulations</b> using data-driven models
      																	<ul>
      																		<li>Essential tool for validating/calibrating pipelines</il>
      																	</ul>
      																</il>
      																<br>

      																<li class="fragment"> Provide <b>data-driven priors</b> for imaging inverse problems
      																	<ul>
      																		<li> Application to deblending, but also deconvolution, inpainting, anomaly detecion.</li>
      																	</ul>
      																</li>
      																<br>
      															</ul>
      													</div>
      												</div>

      													<br>
      										<div class="fragment">
      												<u>Advertisement:</u>
                              <br>
      												<br>
      													<ul>
      														<li> <a href="https://github.com/ml4astro/galaxy2galaxy">Galaxy2Galaxy (github.com/ml4astro/galaxy2galaxy)</a>: Repository of models and datasets for accelerating research in ML for astro.
      														</li>

      														<br>

      														<li> <a href="https://gitter.im/ml4astro/GalaxyEmulationTaskForce">Galaxy Emulation Task Force (gitter.im/ml4astro/GalaxyEmulationTaskForce)</a>: Group of people working on applications of generative models to the study of galaxies, join the conversation :-) .
      														</li>

      													</ul>
      												</div>

      													<br>
      												<p class="fragment">Thank you ! </p>
      																		 <br> <br>


      						</section>


			</div>
		</div>


    		<style>
    		/* .reveal .slides {
    		    border: 5px solid red;
    		    min-height: 100%;
    		    width: 128mm;
    		    height: 96mm;
    		} */

    		.reveal .block {
    			background-color: #191919;
    			margin-left: 20px;
    			margin-right: 20px;
    			text-align: left;
    			padding-bottom: 0.1em;
    		}

    		.reveal .block-title {
    			background-color: #333333;
    			padding:8px 35px 8px 14px;
      		color: #FFAA7F;
      		font-weight: bold;
    		}

    		.reveal .block-content {
    			padding:8px 35px 8px 14px;
    		}

    		.reveal .slide-title {
    			border-left: 5px solid white;
    			text-align: left;
    			margin-left: 20px;
    			padding-left: 20px;
    		}

    		.reveal .alert {
      		color: #FFAA7F;
      		font-weight: bold;
    		}

    		.reveal .inverted {
    			filter: invert(100%);
    		}
    /*
    	    /* .reveal .alert {
    	             padding:8px 35px 8px 14px; margin-bottom:18px;
    	             text-shadow:0 1px 0 rgba(255,255,255,1);
    	             border:5px solid #FFAA7F;
    	             -webkit-border-radius: 14px; -moz-border-radius: 14px;
    	             border-radius:14px
    	             background-position: 10px 10px;
    	             background-repeat: no-repeat;
    	             background-size: 38px;
    	             padding-left: 30px; /* 55px; if icon
    	     }
    	     .reveal .alert-block {padding-top:14px; padding-bottom:14px}
    	     .reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
    	     /*.reveal .alert li {margin-top: 1em}
    	     .reveal .alert-block p+p {margin-top:5px} */

    		</style>

		<script src="reveal.js/js/reveal.js"></script>

    <script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: false,

				//center: false,
				hash: true,

				// Visibility rule for backwards navigation arrows; "faded", "hidden"
				// or "visible"
				controlsBackArrows: 'hidden',

				// Display a presentation progress bar
				progress: true,

				// Display the page number of the current slide
				slideNumber: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// The "normal" size of the presentation, aspect ratio will be preserved
				// when the presentation is scaled to fit different resolutions. Can be
				// specified using percentage units.
				width: 1280,
				height: 720,

				// Factor of the display size that should remain empty around the content
				margin: 0.1,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 1.5,

				dependencies: [
					{ src: 'reveal.js/plugin/markdown/marked.js' },
					{ src: 'reveal.js/plugin/markdown/markdown.js' },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true },
					{ src: 'reveal.js/plugin/math/math.js', async: true },
					{ src: 'reveal.js/plugin/reveal.js-d3/reveald3.js' },
					{ src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js' },
					{ src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js' },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true }
				]

			});
		</script>
	</body>
</html>

<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Taming Implicit Distributions with Generative Modeling</title>

	<meta name="description" content="Likelihood-Free in Paris, April 20th 2022">
	<link rel="stylesheet" href="reveal.js/dist/reset.css">
	<link rel="stylesheet" href="reveal.js/dist/reveal.css">
	<link rel="stylesheet" href="reveal.js/dist/theme/darkenergy.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section data-background-iframe="background.html">
				<div class="container">
					<div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
						<h1>Taming Implicit Distributions with Generative Modeling</h1>
						<h2>Likelihood-Free in Paris, April 20th 2022</h2>
					</div>
				</div>
				<hr>
				<div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0);">
					<div class="container">
						<div class="col">
							<div align="left" style="margin-left: 20px;">
								<h2>Fran√ßois Lanusse</h2>
								<br>
								<img src="assets/CosmoStatDarkBK.png" class="plain"></img>
								<br>
							</div>
						</div>

						<div class="col">
							<br>
							<br>
							<br>
							<br>
							<img src="assets/logo_cnrs.png" class="plain" height="150"></img>
						</div>

						<div class="col">
							<br>
							<br>
							<br>
							<img src="assets/aim.png" class="plain" height="150"></img>
						</div>
					</div>
					<div> slides at <a href="https://eiffl.github.io/talks/Paris2022">eiffl.github.io/talks/Paris2022</a> </div>
				</div>
			</section>

					<!-- <section data-background-image="assets/WMAP_timeline_large.jpg">
						<h3 class='slide-title' style="position:absolute;top:0;"> the $\Lambda$CDM view of the Universe </h3>
						<br> <br>
						<div class="container">
							<div class="col" style="flex: 0 0 40em;">

							</div>
							<div class="col">

								<img class="plain" data-src="assets/Euclid.png" style="width: 300px" />

								<img class="plain" data-src="assets/wfirstlogo.png" style="width: 300px" />

								<img class="plain" data-src="assets/vrro.png" style="width: 300px" />
							</div>
						</div>
						<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
					</section> -->

						<section>
							<section data-background-video="assets/animation-day-to-night.mov" data-background-video-muted>
								<h3 class='slide-title'>the Rubin Observatory Legacy Survey of Space and Time</h3>
								<div class="container">
									<div class="col">
										<ul>
											<li class="fragment fade-up"> 1000 images each night, 15 TB/night for 10 years</li>
											<br>
											<li class="fragment fade-up"> 18,000 square degrees, observed once every few days</li>
											<br>
											<li class="fragment fade-up"> Tens of billions of objects, each one observed $\sim1000$ times</li>
										</ul>
									</div>

									<div class="col">
										<video data-autoplay class="fragment fade-up" data-fragment-index="1" data-src="assets/obsim.mp4" type="video/mp4" />
									</div>
								</div>
							</section>

							<section data-transition="fade-in fade-out" data-background="assets/gal_sdss.png" data-vertical-align-top>
								<p>Previous generation survey: SDSS</p>
								<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
								<br> <br> <br> <br> <br> <br> <br>
								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
							</section>
							<section data-transition="fade-in fade-out" data-background="assets/gal_des.png" data-vertical-align-top>
								<p>Current generation survey: DES</p>
								<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
								<br> <br> <br> <br> <br> <br> <br>
								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
							</section>
							<section data-transition="fade-in fade-out" data-background="assets/gal_hsc.png" data-vertical-align-top>
								<p>LSST precursor survey: HSC</p>

								<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
								<br> <br> <br> <br> <br> <br> <br>
								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
							</section>
						</section>

						<section>
						<section>
							<h3 class="slide-title">We need to rethink all stages of data analysis</h3>

							<div class="r-stack">
								<div class="fragment current-visible" data-fragment-index="0">
									<img data-src="assets/hsc_shredded.png" style="height:400px;"/><br>
									<div class="fragment" data-fragment-index="0" style="float:right; font-size: 20px">Bosch et al. 2017</div>
								</div>

								<div class="fragment current-visible" data-fragment-index="1">
									<img data-src="assets/deepmass_sims_clean.png" style="height:400px;"/><br>
									<div class="fragment" data-fragment-index="1" style="float:right; font-size: 20px">Jeffrey, <b>Lanusse</b>, et al. 2020</div>
								</div>

								<div class="fragment" data-fragment-index="2">
									<img  data-src="assets/ScatteringTransform.png" style="height:400px;"/> <br>
									<div class="fragment" data-fragment-index="2" style="float:right; font-size: 20px">Cheng et al. 2020</div>
								</div>
							</div>
							<ul>
								<li class="fragment" data-fragment-index="0">Galaxies are no longer blobs.</li>
								<li class="fragment" data-fragment-index="1">Signals are no longer Gaussian.</li>
								<li class="fragment" data-fragment-index="2">Cosmological likelihoods are no longer tractable.</li>
							</ul>
							<br>
							<br>
							<div class="fragment">$\Longrightarrow$ This is the <b class="alert">end of the analytic era</b>...</div>
						</section>

						<section>
							<h3 class="slide-title">... but the <b class="alert">beginning of the data-driven era</b></h3>
								<br>
								 <div class="container">
									 <div class="col fragment">
										 	<b>Case I</b>: Examples from data, no accurate physical model<br>
										 	<img data-src="assets/real_gal-inv-small.png" style="height:400px;"/><br>
												<div style="float:right; font-size: 20px">Mandelbaum et al. 2014</div>
												<br>
									 </div>

									 <div class="col fragment">
										 <b>Case II</b>: Physical model only available as a simulator<br>
										 <img data-src='assets/convergence.png' style="height:400px;"/><br>
											 <div style="float:right; font-size: 20px">Osato et al. 2020</div>
											 <br>
									 </div>
								 </div>
								 <br>
								 <div class="fragment">$\Longrightarrow$ Examples of <b class="alert">implicit distributions</b>: we have access to samples $\{x_0, x_1, \ldots, x_n \}$
									 but <b>we cannot evaluate $p(x)$</b>.
								 </div>
						</section>
					</section>

					<section class="inverted" data-background="#000">
						<h2>How can we leverage implicit distributions <br> for Bayesian inference?</h2>
					</section>

			      			<section>
			      				<section>
			      					<h3 class="slide-title"> The answer is: Deep Generative Modeling</h3>
			      					<br>
			      					<ul>
			      						<li>The goal of generative modeling is to <b>learn an <b class="alert">implicit</b> distribution $\mathbb{P}$</b>
			      							from which the <b>training set $X = \{x_0, x_1, \ldots, x_n \}$</b> is drawn.
			      						</li>
			      						<br>
			      						<li class='fragment'> Usually, this means building a parametric model $\mathbb{P}_\theta$
			      							that tries to be close to $\mathbb{P}$.
			      						</li>
			      					</ul>

			      					<br>
			      					<div class="container">
			      						<div class="col fragment fade-up">
			      							<img data-src="https://s3.amazonaws.com/media-p.slid.es/uploads/866922/images/7756538/pasted-from-clipboard.png" class="plain"></img>
			      							<br>
			      							True $\mathbb{P}$
			      						</div>

			      						<div class="col  fragment fade-up">
			      							<img data-src="https://s3.amazonaws.com/media-p.slid.es/uploads/866922/images/7756539/pasted-from-clipboard.png" class="plain"></img>
			      							<br>
			      							Samples $x_i \sim \mathbb{P}$
			      						</div>

			      						<div class="col  fragment fade-up">
			      							<img data-src="https://s3.amazonaws.com/media-p.slid.es/uploads/866922/images/7756554/pasted-from-clipboard.png" class="plain"></img>
			      							<br>
			      							Model $\mathbb{P}_\theta$
			      						</div>
			      					</div>
			      					<br>
			      					<br>
			      					<ul>
			      						<li class="fragment"> Once trained, you can typically <b>sample from $\mathbb{P}_\theta$</b> and/or <b class="alert">evaluate the likelihood $p_\theta(x)$</b>.
			      						</li>
			      					</ul>

			      				</section>

			      				<section>
			      					<h3 class="slide-title">Why isn't it easy?</h3>
			      					<br>
			      					<ul>
			      						<li> The <b class="alert">curse of dimensionality</b> put all points far apart in high dimension
			      						</li>
			      					</ul>
			      					<div class="container">
			      						<div class="col fragment fade-up">
			      							<img data-src="https://s3.amazonaws.com/media-p.slid.es/uploads/866922/images/7756597/pasted-from-clipboard.png" class="plain"></img>
			      						</div>

			      						<div class="col fragment fade-up">
			      							<img style="height:350px;" data-src="https://developers.google.com/machine-learning/clustering/images/CurseofDimensionality.svg" class="plain"></img>
			      							<br>Distance between pairs of points drawn from a Gaussian distribution.
			      						</div>
			      					</div>

			      					<br>
			      					<ul>
			      						<li class="fragment"><b>Classical methods</b> for estimating probability densities, i.e. Kernel Density Estimation (KDE) start to <b>fail in high dimension</b> because of all the gaps
			      						</li>
			      					</ul>
			      				</section>
										<section>
											<h3 class="slide-title"> The evolution of generative models </h3>

											<br> <br> <br>
											<div class='container'>
												<div class='col'>
													<div style="position:relative; width:500px; height:500px; margin:0 auto;">
														<img class="fragment current-visible plain" data-src="assets/DBN.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="0" />
														<img class="fragment current-visible plain" data-src="assets/vae_faces.jpg" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="1" />
														<img class="fragment current-visible plain" data-src="assets/gan-samples-1.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="2" />
														<img class="fragment plain" data-src="assets/karras2017.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="3" />
													</div>
												</div>

												<div class='col'>
													<ul>
														<li class="fragment" data-fragment-index="0"> Deep Belief Network <br> (Hinton et al. 2006) </li>
														<br>
														<li class="fragment" data-fragment-index="1"> Variational AutoEncoder <br> (Kingma & Welling 2014) </li>
														<br>
														<li class="fragment" data-fragment-index="2"> Generative Adversarial Network <br> (Goodfellow et al. 2014)</li>
														<br>
														<li class="fragment" data-fragment-index="3"> Wasserstein GAN <br> (Arjovsky et al. 2017) </li>
													</ul>
												</div>
											</div>
											<p class="fragment">In this talk, we will focus on models with <b class="alert">tractable log likelihood $p_\theta(x)$</b>: Normalizing Flows & Autoregressive models </p>

										</section>
			      			</section>

<!--
			      			<section>
			      				<h3 class="slide-title"> A visual Turing test </h3>
			      				<div class="container">
			      					<div class="col">
			      						<img data-src="assets/samples_pixel_cnn.png" class="plain" style="height: 500px;"></img>
			      						<br>
			      						<div class="fragment fade-up" data-fragment-index="0"> Fake PixelCNN samples </div>
			      					</div>
			      					<div class="col">
			      						<img data-src="assets/sdss5.png" class="plain" style="height: 500px;"></img>
			      						<br>
			      						<div class="fragment fade-up" data-fragment-index="0"> Real galaxies from SDSS </div>
			      					</div>
			      				</div>
			      			</section> -->

									<!-- <section data-vertical-align-top>
										<h3 class="slide-title" >Not all generative models are created equal</h3>
													<img data-src="assets/generative_models_table.png" class="plain"></img>
								 						<div style="float:right; font-size: 20px">Grathwohl et al. 2018</div>
											<br>
											<br>
										<ul>
											<li> Of particular interest are models with an <b class="alert">explicit $\log p(x)$</b> (not the case of VAEs and GANs).</li>
											<br>
										</ul>
									</section> -->
<!--
					    <section>
					       <h3 class="slide-title">Why are these generative models useful?</h3>

								<b class="alert">Implicit distributions are everywhere!</b>
								<br>
								<br>
								 <div class="container">
									 <div class="col fragment">
										 	<b>Case I</b>: Examples from data, no accurate physical model<br>
										 	<img data-src="assets/real_gal-inv-small.png" style="height:400px;"/><br>
												<div style="float:right; font-size: 20px">Mandelbaum et al. 2014</div>
												<br>
									 </div>

									 <div class="col fragment">
										 <b>Case II</b>: Physical model only available as a simulator<br>
										 <img data-src='assets/convergence.png' style="height:400px;"/><br>
											 <div style="float:right; font-size: 20px">Osato et al. 2020</div>
											 <br>
									 </div>
								 </div>
								 <br>
								 <div class="fragment">$\Longrightarrow$ Generative models <b class="alert">will enable Bayesian inference</b> in cases where
									 implicit distributions are involved, by providing a tractable $p_\theta(x)$.
								 </div>
				      </section> -->

							<section>
								<h3 class="slide-title"> In the rest of this talk</h3>
									<br>
									<br>
								<ul>
									<li > Quantifying Mutual Information </li>
									<br>
									<li > Cosmological Simulation-Based Inference </li>
									<br>
									<li > High-Dimensional Bayesian Inference for Inverse Problems </li>
									<br>
									<li > (time-permitting) Smooth Normalizing-Flows for Sample-Efficient Density Estimation </li>
								</ul>
									<br>
									<br>
							</section>

					<section>
						<h2> Tractable Mutual Information Estimation <br> to Compare LSST Observing Strategies</h2>
						<a href="https://arxiv.org/abs/2104.08229"><img src="https://img.shields.io/badge/astro--ph.IM-arXiv%3A2104.08229-B31B1B.svg" class="plain" style="height:25px;" /></a>
						<a href="https://github.com/aimalz/TheLastMetric"><img src="https://badgen.net/badge/icon/github?icon=github&label" class="plain" style="height:25px;" /></a>
						<hr>
						<div class="container">
							<div class="col">
								<div align="left" style="margin-left: 20px;">
									<h3>Work in collaboration with Alex Malz, John Franklin Crenshaw
									</h3>
									<img data-src="assets/aimalz.gif" style='width:200px; height:200px;object-fit: cover;'></img>
									<img data-src="assets/JFC.png" style='width:200px; height:200px;'></img>

									<br>
									<br>
									$\Longrightarrow$ <b class="alert">Use Neural Density Estimation to estimate Mutual Information</b> from simulations.
								</div>
							</div>
							<div class="col">
								<img class="plain" data-src="assets/mutual_information.png" />
							</div>
						</div>
						<br>
					</section>


					<section>
						<section>
							<h3 class="slide-title">LSST Cadence "Diplomacy"</h3>
							<img data-src="assets/baseline_v2.0_10yrs.gif"/>

							<ul>
								<li class="fragment"> <b>Cadence optimization</b>: How to compare the impact of different survey strategies on a particular science goal?<br>
								<br>
							</ul>
						</section>

						<section>
							<h3 class="slide-title">Traditional approach to evaluate impact on photometric redshifts</h3>

							<ol>
								<li class="fragment">Simulate observed galaxy photometry under different observing strategies</li>
								<li class="fragment">Apply a standard photometric redshift algorithm</li>
								<li class="fragment">Compute ad-hoc "quality metrics"</li>
							</ol>

							<div class="fragment">
							<div class="container">
								<div class="col">
									<img data-src="assets/tlm_outliers.png"/>
								</div>
								<div class="col">
									<img data-src="assets/tlm_zstd.png"/>
								</div>

							</div>
						<smaller>	Outlier fraction and standard deviation for the Color-Matched Nearest-Neighbors (CMNN) photo-$z$ estimator</smaller>
						</div>
						</section>
					</section>

					<section>
						<h3 class="slide-title">Reframing the problem in terms of information </h3>

													<p class="alert">How much information does the photometry under a given observing strategy contains about galaxy redshifts?</p>

					      					<div class="container">

					      						<div class="col">
					      							<img class="plain" data-src="assets/mutual_information.png" />
					      						</div>

					      						<div class="col">
					      							<ul>
					      								<li> Mutual information between $X$ and $Y$:
					      									<blockquote>
					      										&ldquo;"amount of information" obtained about one random variable through observing the other random variable&rdquo;
					      									</blockquote>
					      								</li>
					      								<br>
					      								<li class="fragment">The mutual information can be expressed as:
					      									$$ I(Z ; X_{phot}) \ = \ \mathbb{E}_{z, \mathbf{x}_{phot}} [ \log p( z | \mathbf{x}_{phot}) ] + H(Z) $$
					      								</li>
					      							</ul>
					      						</div>
					      					</div>

													<div class="block fragment">
														<div class="block-title">
															Variational Mutual Information Lower Bound (Barber & Agakov, 2003)
														</div>
														<div class="block-content">
															$$  I(Z ; X_{phot}) \ = \ \underbrace{\mathcal{D}_{KL}\left[ p( z | \mathbf{x}_{phot}) \parallel \log q_\phi( z | \mathbf{x}_{phot}) \right]}_{\geq 0} \ + \ \mathbb{E}_{z, \mathbf{x}_{phot}} [ \log q_\phi( z | \mathbf{x}_{phot}) ] + H(Z) $$
															where $q_\phi$ is a parametric variational distribution, meant to approximate the posterior $p(z | \mathbf{x}_{phot})$.
														</div>
													</div>

													<!-- <div class="block fragment">
														<div class="block-title">
															Observing Strategy Simulations for Photometric Redshifts
														</div>
														<div class="block-content">
															For a set of 6 different survey simulations, we have simulated galaxy catalogs with:
															<ul>
																<li> Fixed true redshift distribution $p(z)$
																</li>

																<li> Simulated $ugrizy$ photometry $\mathbf{x}_{phot}$, different for each survey strategy
																</li>
															</ul>
															<br>
															<div class="fragment">$\Longrightarrow$ This defines an <b>implicit joint distribution $p_{OS}(z, \mathbf{x}_{phot})$</b></div>
														</div>
													</div> -->
					</section>

					<section>
						<h3 class="slide-title">Comparing Mutual Information in Practice</h3>
						<br>
						<br>
						<ol>
								<li>For a set of 6 different survey simulations, we have simulated galaxy catalogs with:
								<ul>
									<li> Fixed true redshift distribution $p(z)$
									</li>

									<li> Simulated $ugrizy$ photometry $\mathbf{x}_{phot}$, different for each survey strategy
									</li>
								</ul>
								<div class="fragment">$\Longrightarrow$ This defines an <b>implicit joint distribution $p(z, \mathbf{x}_{phot})$</b></div>
							</li>
							<br>

							<li class="fragment"> For each observing strategy, train a Conditional Normalizing Flow $q_\phi$ by NLL with:
									$$\mathcal{L} = - \mathbb{E}_{z, \mathbf{x}_{phot}} [ \log q_\phi( z | \mathbf{x}_{phot}) ] $$
							</li>

							<br>

							<li class="fragment"> For each observing strategy, evaluate the Variational Mutual Information Lower Bound as:

								$$VMILB = \mathbb{E}_{z, \mathbf{x}_{phot}} [ \log q_{\phi^*}( z | \mathbf{x}_{phot}) ] + H(Z)$$
							</li>
					</section>

					<section>
						<h3 class="slide-title"> Results </h3>

						<div class="container">
							<div class="col">
							<img data-src="assets/last_metric_plot.png"/><br>
							Variational Mutual Information Lower Bound
						</div>

							<div class="col fragment">
							<img data-src="assets/tlm_outliers.png"/> <br>
							CMNN photo-$z$ Outlier rate
						</div>
						</div>
					</section>


								<section>
									<h2>Simulation-Based Inference <br> by Neural Summarisation and Density Estimation</h2>
									<a href="https://arxiv.org/abs/2009.08459"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2009.08459-B31B1B.svg" class="plain" style="height:25px;" /></a>
									<a href="https://github.com/NiallJeffrey/Likelihood-free_DES_SV"><img src="https://badgen.net/badge/icon/github?icon=github&label" class="plain" style="height:25px;" /></a>
									<hr>
									<div class="container">
										<div class="col">
											<div align="left" style="margin-left: 20px;">
												<h3>Work in collaboration with Niall Jeffrey, Justin Alsing
												</h3>
												<img data-src="assets/niall.jpg" style='width:200px; height:200px;object-fit: cover;'></img>
												<img data-src="assets/justin.jpeg" style='width:200px; height:200px;'></img>

												<br>
												<br>
												$\Longrightarrow$ <b class="alert">Learn an implicit data likelihood</b> from simulations.
											</div>
										</div>
										<div class="col">
											<img class="plain" data-src="assets/ks_sv.png" style="width:350px;" />
										</div>
									</div>
									<br>
								</section>


					      			<section>
					      				<h3 class='slide-title'> limits of traditional cosmological inference </h3>
					      				<div class='container'>
					      					<div class='col'>
					      						<div style="position:relative; width:480px; height:30px; margin:0 auto;">
					      							<div class="fragment current-visible" style="position:absolute;top:0;" data-fragment-index="1">HSC cosmic shear power spectrum</div>
					      							<div class="fragment" style="position:absolute;top:0;" data-fragment-index="2">HSC Y1 constraints on $(S_8, \Omega_m)$</div>
					      						</div>
					      						<div style="position:relative; width:480px; height:300px; margin:0 auto;">
					      							<div class="fragment current-visible" style="position:absolute;top:0;left:0;" data-fragment-index="0">
					      								<img class="plain" data-src="assets/alonso_g1.png" />
					      								<img class="plain" data-src="assets/alonso_g2.png" />
					      							</div>
					      							<img class="fragment current-visible plain" data-src="assets/hsc_correlation_function.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
					      							<img class="fragment  plain" data-src="assets/hsc_constraints.png" style="position:absolute;top:0;left:0;" data-fragment-index="2" />
					      						</div>
					      						<div class="fragment" data-fragment-index="1" style="float:right; font-size: 20px">(Hikage et al. 2018)</div>
					      					</div>

					      					<div class='col'>
					      						<ul>
					      							<li class="fragment" data-fragment-index="0"> Measure the ellipticity $\epsilon = \epsilon_i + \gamma$ of all galaxies<br>
					      								$\Longrightarrow$ Noisy tracer of the weak lensing shear $\gamma$ </li>
					      							<br>
					      							<li class="fragment" data-fragment-index="1"> Compute <b class="alert">summary statistics</b> based on 2pt functions, <br>e.g. the <b>power spectrum</b> </li>
					      							<br>
					      							<li class="fragment" data-fragment-index="2"> Run an MCMC to recover a posterior on model parameters, using an <b class="alert">analytic likelihood</b>
					      								$$ p(\theta | x ) \propto \underbrace{p(x | \theta)}_{\mathrm{likelihood}} \ \underbrace{p(\theta)}_{\mathrm{prior}}$$
					      							</li>
					      						</ul>
					      					</div>
					      				</div>

					      				<div class="block fragment">
					      					<div class="block-title">
					      						Main limitation: the need for an explicit likelihood
					      					</div>
					      					<div class="block-content">
					      						We can only compute the likelihood for <b class="alert">simple summary statistics</b> and on <b class="alert">large scales</b>
					      						<br>
					      						<br>
					      						<div class="fragment"> $\Longrightarrow$ We are dismissing a large amount of information! </div>
					      					</div>
					      				</div>
					      			</section>

					            <section>
					  						<h3 class='slide-title'>A different road: forward modeling</h3>

					  						<div class='container'>
					  							<div class='col'>
					  								<ul>
					  									<li> Instead of trying to analytically evaluate the likelihood,
					  										let us build a forward model of the observables.</li>
					  									<br>
					  								</ul>
					  								<br>
					  								<br>
					  								<br>
					  								<div class="fragment">
					  									$\Longrightarrow$ Learn an <b>implicit likelihood</b> $p(x|\theta)$ given by the <b class="alert">simulator as our physical model</b>
					  								</div>
					  								<br>
					  								<br>
					  								<br>
					  								<br>
					  							</div>

					  							<div class='col'>

					  								<div style="position:relative; width:600px; height:600px; margin:0 auto;">
					  									<img class="plain" data-src="assets/forward_model.png" style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="0" />
					  								</div>
					  							</div>
					  						</div>
					  					</section>

					      			<section>
					      				<section>
					      					<h3 class="slide-title">End-to-end framework for likelihood-free parameter inference with DES SV</h3>
					      					<div class="container">
					      						<div class="col">
					      							<div style="float:right; font-size: 20px"> Jeffrey, Alsing, <b>Lanusse</b> (2021) <a href="https://arxiv.org/abs/2009.08459"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2009.08459-B31B1B.svg" class="plain"
					      										style="height:25px;vertical-align:middle;" /></a></div>
					      						</div>
					      					</div>

					      					<div class="container">
					      						<div class="col">
					      							<img class="plain" data-src="assets/ks_sv.png" style="height:550px;"></img>
					      						</div>

					      						<div class="col fragment">
					      							<img class="plain" data-src="assets/orthant.png" style="height:300px;" />
					      							<img class="plain" data-src="assets/sim_params.png" style="height:300px;" /><br>
					      							Suite of N-body + raytracing simulations: $\mathcal{D}$
					      						</div>
					      					</div>
					      				</section>

												<section>
													<h3>Our method</h3>
													<div class="block fragment">
														<div class="block-title">
															A two-steps approach to inference
														</div>
														<div class="block-content">
															<ul>
																<li> Automatically learn an <b>optimal low-dimensional summary statistic</b>
																	$$y = f_\varphi(\kappa_{KS}) $$
																</li>

																<br>

																<li class="fragment"> Use Neural Density Estimation to build an <b>estimate $p_\phi$ of the likelihood function $p(y \ | \ \theta)$</b> (Neural Likelihood Estimation)
																</li>

																<br>

																<li class="fragment"> Run a conventional Markov Chain Monte Carlo sampling
																</li>

																	</ul>
																</li>
															</ul>
														</div>
													</div>
												</section>

											</section>

											<section>

					      				<section>
					      					<h3 class="slide-title">Learning summary statistics by Variational Mutual Information Maximization</h3>
					      					<br>
					      					<br>
					      					<div class="container">

					      						<div class="col">
					      							<img class="plain" data-src="assets/mutual_information.png" />
					      						</div>

					      						<div class="col">
					      							<ul>
					      								<li> Mutual information between $X$ and $Y$:
					      									<blockquote>
					      										&ldquo;"amount of information" obtained about one random variable through observing the other random variable&rdquo;
					      									</blockquote>
					      								</li>
					      								<br>
					      								<li class="fragment">Given a parametric summarizing function $y = f_\phi(\kappa(\theta))$
					      									<b class="alert">optimizing $f_\phi$ can be done by maximizing $I(y, \theta)$</b>.
					      								</li>
					      								<br>
					      								<li class="fragment">In practice, $f_\phi$ is a CNN, trained to maximize a
					      									variational lower bound on the mutual information:
					      									$$ I(y ; \theta) \ \ge \ \mathbb{E}_{y, \theta} [ \log q_\phi(\theta | y) ] + H(\Theta) $$
					      								</li>
					      							</ul>
					      						</div>
					      					</div>
					      				</section>

					      				<section>
					      					<h3 class='slide-title'> deep residual networks for lensing maps compression</h3>

					      					<div class="container">

					      						<div class="col" style="flex: 0 0 15em;">
					      							<img class="plain" data-src="assets/jeffrey_model.png" style="height:550px" /><br>
					      						</div>
					      						<div class="col">
					      							<ul>
					      								<li> Deep Residual Network $y = f_\phi(x)$ followed by neural density estimator $q_\phi(\theta | y)$
					      								</li>
					      								<br>
					      								<li class="fragment">Training on weak lensing maps simulated for different cosmologies</li>
					      								<div class="container fragment">
					      									<div class="col" style="flex: 0 0 26em;">
					      										<img class="plain" data-src="assets/mass_maps.png" /><br>
					      									</div>
					      									<div class="col">
					      										<img class="plain" data-src="assets/TF_FullColor_Horizontal.png" />
					      										<br>
					      										<br>
					      										<br>
					      										<img class="plain" data-src="assets/google-cloud-platform-logo.png" />
					      									</div>
					      								</div>
					      								<li class="fragment">Training by Variational Mutual Information Maximization:
					      									$$\mathbb{E}_{(x, \theta) \in \mathcal{D}} [ \log q_\phi(\theta | f_\phi(y) ) ]$$
					      								</li>
					      							</ul>
					      						</div>
					      					</div>
					      				</section>
											</section>

											<section>

					      				<section>
					      					<h3 class="slide-title">Estimating the likelihood by Neural Density Estimation</h3>
					      					<br>
					      					$\Longrightarrow$ We cannot assume a Gaussian likelihood for the summary $y = f_\phi(\kappa)$ but we can learn $p(y | \theta)$: Neural Likelihood Estimation.
					      					<br>
					      					<br>
					      					<div class="container">
					      						<div class="col">
					      							<img data-src="assets/flow_dinh_1.png" class="plain fragment fade-up" data-fragment-index="1"></img>
					      							<img data-src="assets/flow_dinh_2.png" class="plain fragment fade-up" data-fragment-index="1"></img>
					      							<br>
					      							<div class="fragment fade-up" style="float:right; font-size: 20px" data-fragment-index="1">Dinh et al. 2016</div>
					      						</div>
					      						<div class="col">
					      							<div class="block fragment fade-up" data-fragment-index="1">
					      								<div class="block-title">
					      									Neural Likelihood Estimation by Normalizing Flow
					      								</div>
					      								<div class="block-content">
					      									<ul>
					      										<li> We use a conditional Normalizing Flow to build an explicit model for the likelihood function
					      											$$ \log p_\varphi (y | \theta)$$
					      										</li>
					      										<br>
					      										<li class="fragment"> In practice we use the pyDELFI package and an <b>ensemble of NDEs</b> for robustness.
					      										</li>
					      										<br>
					      										<li class="fragment"> Once learned, we can use the likelihood as part of a conventional MCMC chain</li>
					      									</ul>
					      								</div>
					      							</div>
					      							<br>
					      							<br>
					      						</div>
					      					</div>
					      				</section>

												</section>

					      				<section>
					      					<h3 class="slide-title">Parameter constraints from DES SV data</h3>

					      					<div class="container">
					      						<div class="col">
					      							<img class="plain" data-src="assets/results_jeffrey.png" />
					      						</div>

					      						<div class="col fragment">
					      							<img class="plain" data-src="assets/jeffrey_s8.png" />
					      						</div>
					      					</div>
					      				</section>




																				      <section>
																				      	<h2> Data-driven priors for astronomical inverse problems</h2>

																								<a href="https://arxiv.org/abs/1912.03980"><img src="https://img.shields.io/badge/astro--ph.IM-arXiv%3A1912.03980-B31B1B.svg" class="plain" style="height:25px;" /></a>
																                <a href="https://www.youtube.com/watch?v=oWOU3qNHoL0"><img src="https://img.shields.io/badge/-youtube-red?logo=youtube&labelColor=grey" class="plain" style="height:25px;" /></a>
																				                  <hr>
																				                  <br>
																				                  <div align="left" style="margin-left: 20px;">
																														<div class="container">
																															<div class="col">
																				                  <h3>Work in collaboration with <br>
																				                  Peter Melchior, Fred Moolekamp, Remy Joseph</h3>
																													<br>
																												</div>
																												<div class="col">
																												</div>
																												<div class="col">
																													<img data-src="assets/scarlet_data.png" style="height:450px;"/>
																												</div>
																												</div>
																				                  </div>
																				                  <br>
																				                  <br>
																				      </section>

																				      <section>
																				      <section data-background="assets/gal_hsc.png">

																				      </section>
																				 				<section>
																				 					<h3 class="slide-title">The challenge of galaxy blending</h3>
																											<div class="container">
																													<div class="col">
																														<div style="position:relative; width:480px; height:500px; margin:0 auto;">
																															<img class="fragment current-visible plain"  data-src="assets/hsc_deblending_success.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																															<img class="fragment plain" data-src="assets/hsc_shredded.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																														</div>
																														<div class="fragment" data-fragment-index="0" style="float:left; font-size: 20px">Bosch et al. 2017</div>
																													</div>
																													<div class="col">
																													<ul>
																														<li class="fragment fade-up" data-fragment-index="0"> In HSC over 60% of all galaxies are blended</li>
																														<br>
																														<li class="fragment fade-up" data-fragment-index="0"> Important impact on our main cosmological probes</li>
																														<br>
																														<li class="fragment fade-up" data-fragment-index="1"> Current generation of deblenders does not meet our target requirements</li>
																														<br>
																														<ul class="fragment fade-up" data-fragment-index="2">
																															<li> Existing methods rely on simple assumptions about galaxy profiles, like <i>symmetry</i> or <i>monotonicity</i></li>
																														</ul>
																													</ul>
																													</div>
																											</div>

																											<div class="fragment fade-up"data-fragment-index="3" >
																												Deblending is an ill-posed inverse problem, akin to <i>Blind Source Separation</i>. The is no <b>single solution</b>.<br>
																												$\Longrightarrow$ Intuitively, the key will be to leverage an understanding of how individual <i>galaxies look like</i>.
																											</div>
																				 				</section>
																								</section>

																								<!--

																								<section>
																									<section>
																									<h3 class="slide-title">Deep Learning applied to deblending (Reiman & Gohre 2018)</h3>
																												<div>
																												<img class="plain" data-src="assets/Reiman2018_1.png" />
																													Branched GAN model for deblending
																												</div>

																											<div class="block fragment">
																												<div class="block-title">
																													The issue with <i>black-box</i> models
																												</div>
																												<div class="block-content">
																													<ul>
																														<li> No explicit control of noise, PSF, depth, number of sources.
																																<ul>
																																	<li> Model would have to be retrained for all observing configurations
																																	</li>
																																</ul>
																														</li>
																														<br>
																														<li> No guarantees on the network output (e.g. flux preservation, artifacts)
																														</li>
																													</ul>
																											</div>
																										</div>
																									</section>

																									<section>
																												<img class="plain" data-src="assets/Reiman2018_2.png"/>
																									</section>
																								</section> -->

																								<section>
																								<!-- <section>
																									<h3 class="slide-title">Linear inverse problems</h3>

																									$\boxed{y =  \mathbf{A}x + n}$
																									<br>
																									<br>
																									$\mathbf{A}$ is known and encodes our physical understanding of the problem.
																									<span class="fragment"><br>$\Longrightarrow$ When non-invertible or ill-conditioned, the inverse problem is ill-posed with no unique solution $x$</span>
																									<div class="container fragment fade-up">
																											<div class="col">
																												<img data-src="assets/pluto_smooth.png" class="plain"></img>
																												Deconvolution
																											</div>
																											<div class="col">
																												<img data-src="assets/pluto_missing.png" class="plain"></img>
																												Inpainting
																											</div>
																											<div class="col">
																												<img data-src="assets/plutoNoise.png" class="plain"></img>
																												Denoising
																											</div>
																									</div>

																								</section> -->

																								<section data-vertical-align-top>
																									<h3 class="slide-title">A Bayesian view of the problem</h3>
																									$\boxed{y =  \mathbf{A}x + n}$
																									<br>

																									<br>
																									<div class="fragment">
																									$$ p(x | y) \propto p(y | x) \ p(x) $$
																									</div>
																									<br>

																									<ul>
																										<li class="fragment fade-up">$p(y | x)$ is the data likelihood, which <b>contains the physics</b><br>
																										</li>
																										<br>
																										<li class="fragment fade-up">$p(x)$ is our prior knowledge on the solution.</li>
																									</ul>
																									<br>
																									<br>
																									<div class="fragment fade-up">
																									With these concepts in hand, we want to estimate the Maximum A Posteriori solution:
																									<br>
																									<br>
																									$$\hat{x} = \arg\max\limits_x \ \log p(y \ | \ x)  + \log p(x)$$
																									<br>
																									For instance, if $n$ is Gaussian, $\hat{x} = \arg\max\limits_x \ - \frac{1}{2} \parallel y - \mathbf{A} x \parallel_{\mathbf{\Sigma}}^2 + \log p(x)$
																									</div>
																									<br>
																									<div class="fragment fade-up">
																										<h3>How do you choose the prior ?</h3>
																									</div>
																								</section>

																								<section>
																									<h3 class="slide-title"> Classical examples of signal priors </h3>
																										<div class="container">
																											<div class="col">
																												Sparse
																												<img data-src="assets/wavelet.png" height="400" class="plain"></img><br>
																												$$ \log p(x) = \parallel \mathbf{W} x \parallel_1 $$
																											</div>
																											<div class="col">
																												Gaussian
																												<img data-src="assets/zknj8.jpg" height="400" class="plain"></img>
																												$$ \log p(x) = x^t \mathbf{\Sigma^{-1}} x $$
																											</div>
																											<div class="col">
																												Total Variation
																												<img data-src="assets/shepp-Logan.ppm" class="plain"></img>
																												$$ \log p(x) = \parallel \nabla x \parallel_1 $$

																											</div>
																									</div>
																								</section>

																								<section data-background="assets/hsc_screen.png">
																										<h2>But what about this?</h2>

																								</section>
																							</section>

																							<!-- <section class="inverted" data-background="#000">
																								<h2>
																								Can we use Deep Learning to learn the prior from data?</h2>
																							</section> -->
												<!--
																							<section>
																								<h3 class="slide-title" >A deblending toy example</h3>
																								<div class="container">
																								<div class="col">
																										<div class="fig-container" data-file="dgm_prior.html" data-style="height: 550px;"></div>
																										<br>
																										Try me out at: <a href="https://eiffl.github.io/DeepPriors">https://eiffl.github.io/DeepPriors</a>
																								</div>

																							 <div class="col">
																								 <ul>
																									 <li>Assume a blend with two components $x_1$ and $x_2$ <br> $x_1 + x_2$ must match the data $y$</li>
																									 <br>
																									 <li>Each component of the blend should lie on the "realistic galaxy manifold", symbolized by the two-moons distribution.</li>
																								 </ul>
																								 <p> We are solving: </p>
																									 $\arg \max - \frac{1}{2} \parallel {\color{Orchid} y} - {\color{red} \sum_{\color{red} i} {\color{red} x}_{\color{red} i}} \parallel_2^2 + \log p({\color{SkyBlue} x_{\color{SkyBlue} 1}}) + \log p({\color{GreenYellow} x_{\color{GreenYellow} 2}}) $
																									 <br>
																									 <br>
																									 This can be done by gradient descent as long  as one has access to $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d \color{orange}x}$.
																						 	 </div>
																					 </div>
																						</section> -->
																							<!-- <section data-vertical-align-top>
																								<h3 class="slide-title" >Not all generative models are created equal</h3>
																											<img data-src="assets/generative_models_table.png" class="plain"></img>
																						 						<div style="float:right; font-size: 20px">Grathwohl et al. 2018</div>
																									<br>
																									<br>
																								<ul>
																									<li> GANs and VAEs are very common and successfull but do not fit our purposes.</li>
																									<br>
																									<li> We need a model which can provide explicitly $\log p(x)$.</li>
																									<br>
																								</ul>
																							</section> -->

																							<section>
																								<h3  class="slide-title">PixelCNN: Likelihood-based Autoregressive generative model</h3>
																								<br>
																								<br>
																								<div class="container">
																								<div class="col">
																										Models the probability $p(x)$ of an image $x$ as:
																										$$ p_{\theta}(x) = \prod_{i=0}^{n} p_{\theta}(x_i | x_{i-1} \ldots x_0) $$
																										<ul>
																												<li class="fragment">$p_\theta(x)$ is explicit! We get a number out.</li>
																												<br>
																												<li class="fragment">We can train the model to learn a distribution of isolated galaxy images.</li>
																												<br>
																												<li class="fragment">We can then evaluate its gradient $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d \color{orange}x}$.</li>
																										</ul>
																										<br>
																										<br>
																								</div>

																								<div class="col">
																										<img data-src="assets/pixel_cnn_conv.png" class="plain"></img>
																						 				<div style="float:right; font-size: 20px">van den Oord et al. 2016</div>
																								</div>
																							 </div>

																							 <br>
																							 <ul>
																								 <li class="fragment"> Check out another application of these models to <b>discrimination between real (SDSS) and simulated (Illustris TNG)</b>
																									 galaxy populations: <a href="https://arxiv.org/abs/2007.00039">Zanisi, Huertas-Company, <b>Lanusse</b> et al. 2020 arXiv:2007.00039</a></li>
																							 </ul>
																							</section>

																				  		<section>
																				  				<h3 class="slide-title">Getting started with Deep Priors: deep denoising example</h3>
																				  				$$ \boxed{{\color{Orchid} y}  = {\color{SkyBlue} x} + n} $$
																				  													<div class="container">
																				  														<div class="col">
																				  															<div style="position:relative; width:550px; height:550px; margin:0 auto;">
																				  																		<img class="fragment current-visible plain" data-src="assets/points.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																				  																		<div class="fig-container fragment" data-file="dgm_prior_denoising.html" data-style="height: 550px;width: 550px;" style="position:absolute;top:0;left:0;" data-fragment-index="1"></div>
																				  															</div>
																				  															<!-- <img data-src="assets/points.png"/>
																				  															<div class="fig-container" data-file="dgm_prior_denoising.html" data-style="height: 550px;"></div> -->

																				  														</div>

																				  														<div class="col">
																				  															<ul>
																				  																<li class="fragment" data-fragment-index="0" > Let us assume we have access to examples of $ {\color{SkyBlue} x}$ without noise.</li>
																				  																<br>
																				  																<li class="fragment"  data-fragment-index="1">We learn the <b class="alert">distribution of noiseless data $\log p_\theta(x)$</b> from samples using a deep generative model.</li>
																				  																<br>
																				  																<!-- <li class="fragment"> We measure a noisy ${\color{Orchid} y}$ and we want to estimate a denoised ${\color{SkyBlue} x}$</li>
																				  																<br> -->
																				  																<li class="fragment">The solution should lie on the <b class="alert">realistic data manifold</b>, symbolized by the two-moons distribution.
																				  																	<div class="fragment">
																				  																	<p> We want to solve for the Maximum A Posterior solution: </p>
																				  																	$$\arg \max - \frac{1}{2} \parallel {\color{Orchid} y} - {\color{SkyBlue} x} \parallel_2^2 + \log p_\theta({\color{SkyBlue} x})$$

																				  																	This can be done by <b>gradient descent</b> as long as one has access to the <b class="alert">score function</b> $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d \color{orange}x}$.
																				  																</div>
																				  																</li>
																				  															</ul>
																				  													</div>
																				  										</div>
																				  										</section>

																							<section>
																								<h3 class="slide-title"> The Scarlet algorithm: deblending as an optimization problem</h3>
																										<div style="float:right; font-size: 20px">Melchior et al. 2018</div>

																										$$ \mathcal{L} = \frac{1}{2} \parallel \mathbf{\Sigma}^{-1/2} (\ Y - P \ast A S \ ) \parallel_2^2 - \sum_{i=1}^K \log p_{\theta}(S_i) + \sum_{i=1}^K g_i(A_i) +  \sum_{i=1}^K f_i(S_i)$$

																								<div class="container">
																								<div class="col">
																										<img data-src="assets/scarlet_data.png" height=450 class="plain"></img>
																								</div>

																								<div class="col">

																									Where for a $K$ component blend:
																									<br>
																										<ul>
																										<li>$P$ is the convolution with the instrumental response</li>
																										<br>
																										<li>$A_i$ are channel-wise galaxy SEDs, $S_i$ are the morphology models</li>
																										<br>
																										<li>$\mathbf{\Sigma}$ is the noise covariance</li>
																										<br>
																										<li>$\log p_\theta$ is a PixelCNN prior</li>
																										<br>
																										<li>$f_i$ and $g_i$ are arbitrary additional non-smooth consraints, e.g. positivity, monotonicity...</li>
																										</ul>
																								</div>
																							</div>

																							<span class="fragment fade-up">$\Longrightarrow$ Explicit physical modeling of the observed sky</span>
																							</section>

																							 <section>
																								<h3  class="slide-title">Training the morphology prior</h3>

																								<div class="container">
																									<div class="col">
																										<img data-src="assets/cosmos_training.png" height=450 class="plain"></img>
																										<div> Postage stamps of isolated COSMOS galaxies used for training, at WFIRST resolution and fixed fiducial PSF</div>
																								</div>

																								<div class="col">
																								<div class="container fragment fade-in">
																									<div class="col">
																										isolated galaxy
																									<img data-src="assets/gal_1.png" class="plain"></img>
																									<span> $\log p_\theta(x) = 3293.7$ </span>
																								</div>

																									<div class="col">
																										artificial blend
																									<img data-src="assets/gal_2.png" class="plain"></img>
																									<span> $\log p_\theta(x) = 3100.5 $ </span>
																								</div>
																									</div>
																								</div>
																							</section>

																							<section>
																								<section>
																								<h3 class="slide-title">Scarlet in action</h3>

																								<div class="container">
																									<div class="col">
																										Input blend
																									<div style="position:relative; width:480px; height:480px; margin:0 auto;">
																									<img data-src="assets/scar_input.png" class="plain"></img>
																								</div>
																									</div>

																								<div class="col">
																									<span class="fragment" data-fragment-index="0">Solution</span>
																									<div style="position:relative; width:480px; height:480px; margin:0 auto;">
																											  <img class="fragment current-visible plain" data-src="assets/old_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																											  <img class="fragment  plain" data-src="assets/pix_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																									</div>
																								</div>

																								<div class="col">
																									<span class="fragment" data-fragment-index="0">Residuals</span>
																									<div style="position:relative; width:480px; height:480px; margin:0 auto;">
																											  <img class="fragment current-visible plain" data-src="assets/old_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																											  <img class="fragment  plain" data-src="assets/pix_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																									</div>
																								</div>
																								</div>

																								<ul>
																										<li class="fragment fade-up" data-fragment-index="0">Classic priors (monotonicity, symmetry).</li>
																										<br>

																										<li class="fragment fade-up" data-fragment-index="1">Deep Morphology prior.</li>
																								</ul>

																							</section>
																							<section>
																								<div class="container">
																									<div class="col">
																										True Galaxy
																									<img data-src="assets/true_input.png" class="plain"></img>
																								</div>

																								<div class="col">
																									Deep Morphology Prior Solution
																												<img class=" plain" data-src="assets/pix_rec2.png"  />
																								</div>

																								<div class="col">
																									Monotonicity + Symmetry Solution
																												<img class=" plain" data-src="assets/scar_rec2.png" />
																									</div>
																								</div>
																							</section>
																							</section>


																				      <section>
																								<h3 class="slide-title"> Extending to multi-band images</h3>

																										<img class=" plain" data-src="assets/scarlet_hsc.png" />

																				      </section>


																					      <section>
																					        <h3 class="slide-title">Going beyond MAP estimation: Full high-dimensional posterior sampling</h3>
																					        <div class="container">
																					          <div class="col">
																					            <ul>
																					              <li><em>Probabilistic Mass Mapping with Neural Score Estimation</em><br> B. Remy, <b> F. Lanusse</b>, N. Jeffrey et al. 2022<br>
																					                <a href="https://arxiv.org/abs/2201.05561"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2201.05561-B31B1B.svg" class="plain" style="height:25px;" /></a>
																					              </li>
																					            </ul>
																					            <img class=" plain" data-src="assets/cropped.gif" />
																					            <br> <br>

																					          </div>
																					          <div class="col fragment">
																					            <ul>
																					              <li><em>Denoising Score-Matching for Uncertainty Quantification in Inverse Problems</em><br> Z. Ramzi, B. Remy, <b>F. Lanusse</b>, P. Ciuciu, J.L. Starck<br>
																					                <a href="https://arxiv.org/abs/2011.08698"><img src="https://img.shields.io/badge/stat.ML-arXiv%3A2011.08698-B31B1B.svg" class="plain" style="height:25px;" /></a>
																					              </li>
																					            </ul>
																					            <img class="plain" data-src="assets/knee.gif" style="height:410px;"/>
																					          </div>
																					        </div>
																									<p class="alert fragmeent"> See Benjamin Remy's talk tomorrow to learn all about that! </p>
																					      </section>
<!--

																							<section>
																								<h3 class="slide-title"> Takeaway message</h3>

																								<br>
																								<br>
																								<br>

																				        <ul>
																				          <li> We have introduce an <b class="alert">hybrid physical/deep learning model for inverse problems</b>
																				            <ul>
																				              <br>
																				              <li class="fragment"> Incorporate prior astrophysical knowledge as a data-driven prior
																				              </li>
																				              <br>

																				              <li class="fragment"> Interpretable in terms of physical components of the astronomical scene
																				              </li>
																				              <br>
																				              <br>

																				              <li class="fragment"> Can accomodate different observing conditions and instruments
																				                <br> $\Longrightarrow$ For instance, for the joint modeling of  LSST/Euclid data
																				              </li>
																				            </ul>
																				          </li>

																				          <br>
																				          <br>
																				              <br>
																								<br>

																				          <!-- <li class="fragment"> We are now in the process of evaluating the benefits of the approach compared to standard scarlet.
																				            Some potential complications:
																				            <ul>
																				              <li> Accounting for color gradients in this new model
																				              </li>
																				              <br>
																				              <li> Evaluating prior-induced biases on lensing related quantities.
																				              </li>
																				            </ul>
																				          </li>
																				        </ul>

																							</section> -->

			<section>
				<h2>Smooth Normalizing Flows <br> for sample-efficient Density Estimation</h2>
				<hr>
				<div class="container">
					<div class="col">
						<div align="left" style="margin-left: 20px;">
							<h3>Work in collaboration with <br> Justine Zhegal, Benjamin Remy
							</h3>
							<img data-src="assets/justine.jpeg" style='width:200px; height:200px;'></img>
							<img data-src="assets/benjamin.png" style='width:200px; height:200px;object-fit: cover;'></img>
							<br>
							<br>
							$\Longrightarrow$ Normalizing Flows with <b class="alert">well-defined scores</b> to enable training by score-matching.
						</div>
					</div>
					<div class="col">
						<img class="plain" data-src="assets/flow_score.png" />
					</div>
				</div>
				<br>
			</section>


			<section>
				<h3 class="slide-title"> The issue with Density Estimation by</h3>

				<div class="container">
					<div class="col">
						<ul>
							<li>There is a lot more information in the score than in the samples.</li>
						</ul>
					</div>
					<div class="col">
						<ul>
							<li>We might want to regularize the score  </li>
						</ul>

					</div>
				</div>

			</section>





									<section>
										<h1> Conclusion </h1>
									</section>

									<section>
										<h3 class="slide-title"> Conclusion </h3>
										<div class="block ">
											<div class="block-title">
												Merging Deep Learning with Physical Models for Bayesian Inference
											</div>
											<div class="block-content">
												$\Longrightarrow$ Makes <b>Bayesian inference possible</b> at scale and with non-trivial models!
												<br>
												<br>
												<ul>


												<li class="fragment"> Complement known physical models with data-driven components
													<ul>
														<li>Use data-driven generative model as prior for solving inverse problems.</il>
													</ul>
													</il>
													<br>

													<li class="fragment"> Enables inference in high dimension from numerical simulators.
														<ul>
															<li>Automagically construct summary statistics.</li>
															<li>Provides the density estimation tools needed.</li>
														</ul>
														</il>
														<br>



													<li class="fragment"> Differentiable physical models for fast inference
														<ul>
															<li> Differentiability enables Bayesian inference over large scale simulations.</li>
															<li> Models can directly be embedded alongside deep learning components.</li>
														</ul>
													</li>
													<br>
												</ul>
											</div>
										</div>
										<br>

										<br>
										<p class="fragment">Thank you ! </p>
										<br> <br> <br>
									</section>

		</div>
	</div>

	<style>
		.reveal .slides {
			border: 5px solid red;
			min-height: 100%;
			width: 128mm;
			height: 96mm;
		}

		.reveal .block {
			background-color: #191919;
			margin-left: 20px;
			margin-right: 20px;
			text-align: left;
			padding-bottom: 0.1em;
		}

		.reveal .block-title {
			background-color: #333333;
			padding: 8px 35px 8px 14px;
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .block-content {
			padding: 8px 35px 8px 14px;
		}

		.reveal .slide-title {
			border-left: 5px solid white;
			text-align: left;
			margin-left: 20px;
			padding-left: 20px;
		}

		.reveal .alert {
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .inverted {
			filter: invert(100%);
		}

		/*
	/* .reveal .alert {
	padding:8px 35px 8px 14px; margin-bottom:18px;
	text-shadow:0 1px 0 rgba(255,255,255,1);
	border:5px solid #FFAA7F;
	-webkit-border-radius: 14px; -moz-border-radius: 14px;
	border-radius:14px
	background-position: 10px 10px;
	background-repeat: no-repeat;
	background-size: 38px;
	padding-left: 30px; /* 55px; if icon
	}
	.reveal .alert-block {padding-top:14px; padding-bottom:14px}
	.reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
	/*.reveal .alert li {margin-top: 1em}
	.reveal .alert-block p+p {margin-top:5px} */
	</style>


	<script src="reveal.js/dist/reveal.js"></script>
	<script src="reveal.js/plugin/notes/notes.js"></script>
	<script src="reveal.js/plugin/markdown/markdown.js"></script>
	<script src="reveal.js/plugin/highlight/highlight.js"></script>
	<script src="reveal.js/plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			controls: true,

			//center: false,
			hash: true,

			// Visibility rule for backwards navigation arrows; "faded", "hidden"
			// or "visible"
			controlsBackArrows: 'hidden',

			// Display a presentation progress bar
			progress: true,

			// Display the page number of the current slide
			slideNumber: true,

			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// The "normal" size of the presentation, aspect ratio will be preserved
			// when the presentation is scaled to fit different resolutions. Can be
			// specified using percentage units.
			width: 1280,
			height: 720,

			// Factor of the display size that should remain empty around the content
			margin: 0.1,

			// Bounds for smallest/largest possible scale to apply to content
			minScale: 0.2,
			maxScale: 1.5,

			autoPlayMedia: true,

			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath],

			dependencies: [{
					src: 'reveal.js/plugin/markdown/marked.js'
				},
				{
					src: 'reveal.js/plugin/markdown/markdown.js'
				},
				{
					src: 'reveal.js/plugin/notes/notes.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/math/math.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/reveal.js-d3/reveald3.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js'
				},
				{
					src: 'reveal.js/plugin/highlight/highlight.js',
					async: true
				},
			]

		});
	</script>
</body>

</html>

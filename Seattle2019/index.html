<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Deep Generative Models of Galaxy Morphology and Application to Deblending</title>

		<meta name="description" content="Seattle 2019">
		<meta name="author" content="Francois Lanusse">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<link rel="stylesheet" href="reveal.js/css/reset.css">
		<link rel="stylesheet" href="reveal.js/css/reveal.css">
		<link rel="stylesheet" href="reveal.js/css/theme/darkenergy.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="reveal.js/lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

        <section data-background-image="/talks/assets/lsst_stills_0009_crop.jpg" >
            <div class="container">
              <div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
                <h1>Deep Generative Models of Galaxy Morphology</h1>
                <h2>From Image Simulation to Deblending </h2>
            </div>
          </div>

          <hr>
          <div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0);">
              <div class="container" >
                  <div class="col">
                    <div align="left" style="margin-left: 20px;">
                    <br>
                    <h3>Fran√ßois Lanusse</h3>
                    <p>	University of California, Berkeley</p>

                    <img src="/talks/assets/logo_bccp.png" class="plain" height="100"></img>
                    <br>

                    </div>
                  </div>
                  <div class="col">
                    <br>
                    <br>
                    <img src="/talks/assets/bids-logo2.png" class="plain" height="150"></img>
                    <img src="/talks/assets/desc-logo-inv.png" class="plain" height="200"></img>
                  </div>
                </div>
            </div>
          </section>

          <section data-background-image="/talks/assets/WMAP_timeline_large.jpg">
            <h3 class='slide-title' style="position:absolute;top:0;"> the $\Lambda$CDM view of the Universe </h3>
<br>	<br>
            <div class="container">
              <div class="col" style="flex: 0 0 40em;">

              </div>
              <div class="col">

              <img class="plain" data-src="/talks/assets/Euclid.png" style="width: 300px"/>

              <img class="plain" data-src="/talks/assets/wfirstlogo.png" style="width: 300px"/>

              <img class="plain" data-src="/talks/assets/LSST_web_black.png" style="width: 300px"/>
              </div>
            </div>
                <br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
          </section>

          <section>
          <section data-background-video="/talks/assets/animation-day-to-night.mov" data-background-video-muted>
            <h3 class='slide-title'>the Large Synoptic Survey Telescope</h3>
          <div class="container">
          <div class="col">
            <ul>
              <li class="fragment fade-up"> 1000 images each night, 15 TB/night for 10 years</li>
              <br>
              <li class="fragment fade-up"> 18,000 square degrees, observed once every few days</li>
              <br>
              <li class="fragment fade-up"> Tens of billions of objects, each one observed $\sim1000$ times</li>
            </ul>
            <br >
            <!-- <p class="fragment fade-up"> $\Longrightarrow$ Incredible potential for discovery, along with <b>unprecedented challenges</b >.</p> -->
          </div>

         <div class="col">
            <video class="fragment fade-up"  data-fragment-index="1" data-autoplay data-src="/talks/assets/obsim.mp4" type="video/mp4" />
         </div>
       </div>

       </section>

          <section>
          <h3  class='slide-title'>The challenges of modern surveys</h3>
          <div style="float:left;" >
          $\Longrightarrow$  Modern surveys will provide <b>large volumes</b> of <b>high quality</b> data
          </div>
          <br>
          <div class="container">
              <div class="col">

                <div class="block fragment">
                  <div class="block-title">
                    A Blessing
                  </div>
                  <div class="block-content">
                    <ul>
                      <li>Unprecedented statistical power
                      </li>
                      <br>
                      <li>Great potential for new discoveries
                      </li>
                    </ul>
                </div>
              </div>

              <br>
              <div class="block fragment">
                <div class="block-title">
                  A Curse
                </div>
                <div class="block-content">
                  <ul>
                    <li> Existing methods are reaching their limits at every
                      step of the science analysis
                    </li>
                    <br>
                    <li>Control of systematics is paramount
                    </li>
                  </ul>
              </div>
            </div>

            </div>
              <div class="col">
                LSST forecast on dark energy parameters
                <img class="plain" data-src="/talks/assets/LSST_forecast_Y10.png" style="height :400px;"/>
              </div>
          </div>
          <div class="fragment">
          $\Longrightarrow$ Dire need for <b class="alert">novel analysis techniques</b> to fully realize the potential of modern surveys:
          <ul>
            <li class="fragment grow">Low level image processing</li>
            <li>Fast emulation of complex simulations</li>
            <li>Probabilistic inference</li>
          </ul>
        </div>
          </section>

          <section data-transition="fade-in fade-out" data-background="/talks/assets/gal_sdss.png" data-vertical-align-top>
            <p>Previous generation survey: SDSS</p>
            <br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
            <br>	<br>	<br>	<br>	<br>	<br>	<br>
                    <div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
          </section>
          <section data-transition="fade-in fade-out" data-background="/talks/assets/gal_des.png" data-vertical-align-top>
            <p>Current generation survey: DES</p>
            <br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
            <br>	<br>	<br>	<br>	<br>	<br>	<br>
                    <div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
          </section>
          <section data-transition="fade-in fade-out" data-background="/talks/assets/gal_hsc.png" data-vertical-align-top>
              <p>LSST precursor survey: HSC</p>

              <br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>	<br>
              <br>	<br>	<br>	<br>	<br>	<br>	<br>
                      <div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
          </section>
        </section>

        <section>
          <h3  class='slide-title'>Outline of this talk</h3>
          <br>
          <br>
          <br>
          <h3> How can <b>Deep Generative Models</b> help us make sense <br> of increasingly complex images ?</h4>
          <br>
          <br>
          <br>
          <ul>
            <li class="fragment grow">Generative Models for Galaxy Image Simulations</li>
            <br>
            <br>
            <br>
            <li class="fragment grow">Hybrid Physical/Deep Learning Modeling for Astronomical Inverse Problems </li>
            <br>
            <br>
          </ul>
          <br>
          <br>
          <br>
        </section>

        <section>
          <h2>Generative Models for Galaxy Image Simulation</h2>

          <br>
          <br>

          <hr>
          <br>
          <br>
          <div align="left" style="margin-left: 20px;">
          <h3>Work in collaboration with <br>
          Rachel Mandelbaum, Siamak Ravanbakhsh, Barnabas Poczos, Peter Freeman</h3>
          </div>


          <br>
          <br>

          <div style="float:center; font-size: 25px"><b>Lanusse</b> et al., in prep <br>
            Mandelbaum, <b> Lanusse</b>, et al. (2018)<br>
            Ravanbakhsh, <b>Lanusse</b>, et al. (2017)
           </div>

        </section>
        <!-- - Motivation of image simulations from the point of view of shape measurement
             - Illustration on the HSC survey calibration effort
             - Simulating with high degree of realism still very important, blending
             - How do we build science-grade morphology profiles ?
             - Generative models, many different types
             - Visual turing test
             - Why is it more complicated than what might naively think ?
             - How do we learn from corrupted data
              -> We go back to the picture of the simulation process
              -> Introduce graphical model, the key is to have a physical model
             - Introduce Auto-Encoding Variational Bayes
             - Small problems with this setup, aggregate posterior is generally
               not matching the prior, especially if the likelihood is strong
             - Introduce latent space flow for modeling distribution
             - Demonstrate how the dependence is captured
             - Advertisement for Galaxy2Galaxy, and GalSim-Hub
           -->

             <section>
           				<h3 class="slide-title"> The weak lensing shape measurement problem</h3>
								<div>
								<img class="plain" data-src="/talks/assets/great.jpg" />
								</div>

                <div class="block fragment" >
                <div class="block-title">
                  Shape measurement biases
                </div>
                <div class="block-content">
                  $$ < e >  = \ (1 + m) \ \gamma \ + \ c $$

                  <ul>
                    <li class="fragment fade-up"> Can be calibrated on image simulations
                    </li>
                    <li class="fragment fade-up"> How complex do the simulations need to be?
                    </li>
                  </ul>
              </div>
              </div>

             </section>

            <section>
             <section>
           				<h3 class="slide-title"> Image simulations for shear calibration in the HSC survey</h3>
                    <div style="float:right; font-size: 20px">Mandelbaum,<b>Lanusse</b>, Leauthaud, Armstrong, et al. (2018)</div>

								    <img class="plain" data-src="/talks/assets/fig_illustrator_red_2.png" style="height: 450px;"/>

                    <div class="block">
                    <div class="block-title">
                      Hyper Suprime-Cam Subaru Strategic Program
                    </div>
                    <div class="block-content">
                      <ul>
                        <li> 1400 sq. deg. in the wide survey down to 26.4 mag in i-band
                        </li>
                        <li> Essentially a smaller area precursor of LSST
                        </li>
                      </ul>
                  </div>
                  </div>
             </section>

             <section>
               <h3 class="slide-title"> Simulation and Calibration strategy</h3>
               <br>

               <img class="plain" data-src="/talks/assets/simu.png"/>

               <br>
               <br>
               <div class="block">
               <div class="block-title">
                The GREAT3 approach
               </div>
               <div class="block-content">
                 <ul>
                   <li> Input galaxies from deep HST/ACS COSMOS images (25.2 imag)
                   </li>
                   <br>
                   <li> Apply a range of PSFs and noise levels sampled from the survey
                   </li>
                   <br>
                   <li>  Measure response of shape measurement to a known shear
                   </li>
                 </ul>
             </div>
             </div>
             </section>

             <section>

               <h3 class="slide-title"> From simple to complex simulations... </h3>
               <br>

            <div class='container'>
   					<div class='col'>
           <img class="plain" data-src="/talks/assets/HSC_sims.png"/>
             </div>

            <div class='col'>
               <img class="plain fragment fade-left" data-src="/talks/assets/HSC_sims_diff.png"/>
             </div>
           </div>
             </section>

          <section>
            <h3 class="slide-title"> Impact of galaxy morphology</h3>
       				<div class='container'>
       					<div class='col'>
                  <img class="plain" data-src="/talks/assets/real_gal-inv.png" style="height: 350px;"/>
                  <br>
                  <div style="float:left; font-size: 20px">Mandelbaum, et al. (2013), Mandelbaum, et al. (2014)</div>
                </div>

                <div class='col'>
                  <img class="plain fragment fade-up" data-src="/talks/assets/great3_calib2-inv.png" style="height: 425px;"/>
                </div>
              </div>
              <br>

              <div class="block fragment fade-up">
              <div class="block-title">
               The need for data-driven generative models
              </div>
              <div class="block-content">
                <ul>
                  <li> Lack or inadequacy of physical model
                  </li>
                  <li> Extremely computationally expensive simulations
                  </li>
                </ul>
            </div>
            </div>
          </section>
      </section>

			<section class="inverted" data-background="#000">
				<h2>
				Can we learn a model for the signal from the data itself?</h2>
			</section>

   			<section>
   				<h3 class="slide-title"> The evolution of generative models </h3>

   				<br> <br> <br>
   				<div class='container'>
   					<div class='col'>
   						<div style="position:relative; width:500px; height:500px; margin:0 auto;">
   							<img class="fragment current-visible plain" data-src="/talks/assets/DBN.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="0" />
   							<img class="fragment current-visible plain" data-src="/talks/assets/vae_faces.jpg" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="1" />
   							<img class="fragment current-visible plain" data-src="/talks/assets/gan-samples-1.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="2" />
   							<img class="fragment plain" data-src="/talks/assets/karras2017.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="3" />
   						</div>
   					</div>

   			<div class='col'>
   				<ul>
   					<li class="fragment" data-fragment-index="0"> Deep Belief Network <br> (Hinton et al. 2006) </li>
   					<br>
   					<li class="fragment" data-fragment-index="1"> Variational AutoEncoder <br> (Kingma & Welling 2014) </li>
   					<br>
   					<li class="fragment" data-fragment-index="2"> Generative Adversarial Network <br> (Goodfellow et al. 2014)</li>
   					<br>
   					<li class="fragment" data-fragment-index="3"> Wasserstein GAN <br> (Arjovsky et al. 2017) </li>
   				</ul>
   				</div>
   			</div>
   				<br> <br> <br>
   			</section>

        <section>
  				<h3 class="slide-title"> A visual Turing test </h3>
  				<div class="container">
  						<div class="col">
  							<img data-src="/talks/assets/samples_pixel_cnn.png" class="plain" style="height: 500px;" ></img>
  							<br>
  							<div class="fragment fade-up" data-fragment-index="0"> Fake PixelCNN samples </div>
  						</div>
  						<div class="col">
  							<img data-src="/talks/assets/sdss5.png" class="plain"  style="height: 500px;" ></img>
  							<br>
  							<div class="fragment fade-up" data-fragment-index="0"> Real SDSS </div>
  						</div>
  				</div>
  			</section>

      <section>
        <h3 class="slide-title"> Complications specific to astronomical images: spot the differences!</h3>

        <div class="container">
            <div class="col">
              <img data-src="/talks/assets/celeba.png" class="plain" style="height: 450px;" ></img>
              <br>
              CelebA
            </div>
            <div class="col">
              <img data-src="/talks/assets/hsc_images.png" class="plain"  style="height: 450px;" ></img>
              <br>
              HSC PDR-2 wide
            </div>
        </div>
        <br>
        <div >
          <ul>
            <li class="fragment"> There is <b class="alert">noise</b></li>
            <li class="fragment"> We have a <b class="alert">Point Spread Function</b></li>
          </ul>
        </div>
      </section>

      <section>

      <section>
        <h3 class="slide-title">Combining deep generative and physical models</h3>
        <img class="plain" style="height: 200px;" data-src="/talks/assets/simu2.png"/>

        <div class="container fragment fade-up">
            <div class="col">
              <img data-src="/talks/assets/pgm.png" class="plain" style="height: 300px;" ></img>
            </div>
            <div class="col">

              <div class="block">
              <div class="block-title">
               Probabilistic model
              </div>
              <div class="block-content">
                Dataset of $N$ i.i.d. samples $\{x_i \}$ generated from
                $$ x \sim p_{\theta}(x | z, \Sigma, \Pi ) \ p(z) $$
                <ul>
                  <li class="fragment fade-up"> $z$ is a set of latent variables
                  </li>
                  <li class="fragment fade-up"> $\Pi$ is the PSF, $\Sigma$ is the noise covariance
                  </li>
                  <li class="fragment fade-up"> Under a Gaussian noise model:<br>
                    $\qquad p_{\theta}(x | z, \Sigma, \Pi)=\mathcal{N}( \Pi \ast g_\theta(z), \Sigma)$
                  </li>
                </ul>
            </div>
            </div>
            </div>
        </div>
        <div class="fragment"> $\Longrightarrow$ <b class="alert"> Decouples the morphology model from the observing conditions</b>.</div>
      </section>

      <section>
        <h3 class="slide-title">How to train your <s>dragon</s> model</h3>
        <div class="container">
            <div class="col">
              <img data-src="/talks/assets/pgm.png" class="plain" style="height: 300px;" ></img>
            </div>
            <div class="col">
              <ul>
                <li> Training the generative amounts to finding $\theta_\star$ that
                  <b>maximizes the marginal likelihood</b> of the model:
                    $$p_\theta(x | \Sigma, \Pi) = \int \mathcal{N}( \Pi \ast g_\theta(z), \Sigma) \ p(z) \ dz$$
                    <div> $\Longrightarrow$ This is <b class="alert">generally intractable</b></div>
                </li>
                <br>
                <li class="fragment fade-up"> Efficient training of parameter $\theta$ is made possible by <b class="alert">Amortized Variational Inference</b>.
                </li>
              </ul>
            </div>
        </div>

        <div class="block fragment fade-up">
        <div class="block-title">
         Auto-Encoding Variational Bayes (Kingma & Welling, 2014)
        </div>
        <div class="block-content">
          <ul>
            <li class="fragment fade-up"> We introduce a <b>parametric distribution</b> $q_\phi(z | x, \Pi, \Sigma)$ which aims to model the
            posterior $p_{\theta}(z | x, \Pi, \Sigma)$.
            </li>
            <br>
            <li class="fragment fade-up"> Working out the KL divergence between these two distributions leads to:

              $$\log p_\theta(x | \Sigma, \Pi) \quad \geq \quad - \mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right) \quad + \quad \mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]$$

              $\Longrightarrow$ This is the <b>Evidence Lower-Bound</b>, which is differentiable with respect to $\theta$ and $\phi$.
            </li>
          </ul>
      </div>
      </div>

      </section>
      <section>
      <h3 class="slide-title">The famous Variational Auto-Encoder</h3>
      <img data-src="/talks/assets/vae.png" class="plain" style="height: 450px;"> </img>
      <br>
      <br>
      $$\log p_\theta(x| \Sigma, \Pi ) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]}_{\mbox{reconstruction error}} $$
      </section>
      </section>

      <section>
      <section>
  				<h3 class="slide-title"> Illustration on HST/ACS COSMOS images</h3>
            <div class="container">
            <div class="col">
              <img data-src="/talks/assets/Figure_autoencode.png" class="plain" ></img>
              <br>
              <b>Fitting observations</b> with VAE and Bulge+Disk parametric model.
            </div>
            <div class="col">
              <ul>
                <li>Training set: <b>GalSim COSMOS HST/ACS postage stamps</b>
                  <br>
                  <ul>
                    <li> 80,000 deblended galaxies from I < 25.2 sample
                    </li>
                    <li> Drawn on 128x128 stamps at 0.03 arcsec resolution
                    </li>
                    <li> Each stamp comes with:
                      <ul>
                        <li>PSF</li>
                        <li>Noise power spectrum</li>
                        <li>Bulge+Disk parametric fit</li>
                      </ul>
                    </li>
                  </ul>
                </li>
                <br>
                <br>
                <li> Auto-Encoder model:
                  <ul>
                    <li> Deep residual autoencoder:<br> 7 stages of 2 resnet blocs each
                    </li>
                    <li> Dense bottleneck of size 32.
                    </li>
                    <li> Outputs positive, noiseless, deconvolved, galaxy surface brightness.
                    </li>
                  </ul>
                </li>
              </ul>
            </div>
        </div>
      </section>

    <section>
  				<h3 class="slide-title"> Sampling from the model</h3>
            <div class="container">
            <div class="col fragment fade-up">
              <img data-src="/talks/assets/vae_samples_bad.png" class="plain" ></img>
              Woups... what's going on?
            </div>
            <div class="col">
              <img data-src="/talks/assets/latent_space.png" class="plain fragment fade-up" ></img>
            </div>
          </div>
    </section>

    <section>
			<h3 class="slide-title"> Tradeoff between code regularization and image quality</h3>

      <br>
      $$\log p_\theta(x| \Sigma, \Pi ) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]}_{\mbox{reconstruction error}} $$

      <img data-src="/talks/assets/sdss_ae_kl.png" class="plain" ></img>

    </section>

    <section data-background-image=https://media.giphy.com/media/3o85xIO33l7RlmLR4I/source.gif>
    </section>
    </section>

    <section>
    <section>
			<h3 class="slide-title"> Latent space modeling with Normalizing Flows</h3>
      <br>
      $\Longrightarrow$ All we need to do is <b class="alert">sample from the aggregate posterior</b> of the data instead of sampling from the prior.

    <br>
    <br>

    <div class="container">
    <div class="col">
      <img data-src="/talks/assets/flow_dinh_1.png" class="plain fragment fade-up" data-fragment-index="1"></img>
      <img data-src="/talks/assets/flow_dinh_2.png" class="plain fragment fade-up" data-fragment-index="3"></img>

      <br>
		 	<div class="fragment fade-up" style="float:right; font-size: 20px" data-fragment-index="1">Dinh et al. 2016</div>
    </div>
    <div class="col">
              <div class="block fragment fade-up" data-fragment-index="1">
              <div class="block-title">
               Normalizing Flows
              </div>
              <div class="block-content">
                <ul>
                  <li> Assumes a <b class="alert">bijective</b> mapping between
                    data space $x$ and latent space $z$ with prior $p(z)$:
                    $$ z = f_{\theta} ( x ) \qquad \mbox{and} \qquad x = f^{-1}_{\theta}(z)$$
                  </li>
                  <li class="fragment" data-fragment-index="2"> Admits an explicit marginal likelihood:
                    $$ \log p_\theta(x) = \log p(z) + \log \left| \frac{\partial f_\theta}{\partial x}  \right|(x)    $$
                  </li>
                </ul>
            </div>
            </div>
            <br>
              <br>
              <br>
              <br>
    </div>
</div>

    </section>

    <section>
			<h3 class="slide-title"> Conditional sampling in VAE latent space</h3>

    <div class="container">
    <div class="col">
      <img data-src="/talks/assets/conditional_flow.png" class="plain" ></img>
    </div>
      <div class="col">

        <ul>
          <li> We build a latent space model $p_\varphi(z)$ using a Masked Autoregressive Flow (MAF) (Papamakarios, et al. 2017)
          </li>
          <br>
          <li class="fragment"> While we are learning to sample from the latent space, we can also <b class="alert"> learn to sample conditionaly</b>:
                $$  p_\varphi(z | y) $$
          </li>
          <br>

          <li class="fragment"> Here we learn to sample images conditioned on:
            <ul>
              <li> Size: half-light radius $r$
              </li>
              <li> Brightness: I band magnitude $mag\_auto$
              </li>
              <li> Redshift: COSMOS photometric redshift $zphot$
              </li>
            </ul>
          </li>
        </ul>
      </div>
    </div>
  </section>
  </section>

  <section>

  <section>
			<h3 class="slide-title"> Flow-VAE samples</h3>
      <br>
      <br>

      <div style="position:relative; width:1250px; height:700px; margin:0 auto;">
        <img class="current-visible plain" data-src="/talks/assets/flow_vae_samples1.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
        <img class="fragment current-visible plain fade-in" data-src="/talks/assets/flow_vae_samples.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
      </div>
  </section>

  <section>
			<h3 class="slide-title"> Testing conditional sampling</h3>

    <div class="container">
    <div class="col">
      <img data-src="/talks/assets/Figure_flux_error.png" class="plain"></img>

    </div>
    <div class="col">
    <img data-src="/talks/assets/Figure_size_error.png" class="plain fragment fade-up"></img>
    </div>
    </div>

    <div class="fragment">$\Longrightarrow$ We can successfully condition galaxy generation.</div>
  </section>

  <section>
			<h3 class="slide-title"> Testing galaxy morphologies </h3>

      <br>
      <br>

    <img data-src="/talks/assets/gini_m20.png" class="plain"></img>

<br>
<br>


  </section>
</section>

  <section>
			<h3 class="slide-title"> Takeaway message</h3>

      <br>

      <ul>
        <li class="fragment"> We have <b class="alert">combined physical and deep learning components</b> to model
          observed noisy and PSF-convoled galaxy images. <br>
          $\Longrightarrow$ This framework can handle multi-band, multi-resolution, multi-instrument data.
        </li>

        <br>

        <li class="fragment"> We are overcoming the limitations of standard VAEs with an additional latent space model.
          <br>$\Longrightarrow$ Can produce sharp and meaningful images.
        </li>

        <br>

        <li class="fragment"> We demonstrate conditional sampling of galaxy light profiles<br>
          $\Longrightarrow$ Image simulation can be combined with larger survey simulation efforts, e.g. LSST DESC DC2
        </li>
      </ul>


<br>
<br>

      <div class="block fragment fade-up">
      <div class="block-title">
        <b>GalSim Hub</b>
      </div>
      <div class="block-content">

<br>

      <div class="container">
      <div class="col">
        <img data-src="/talks/assets/TF_FullColor_Horizontal.png" class="plain"></img>
      </div>

      <div class="col">

        <ul>

          <li> Framework for sampling from deep generative models
            directly from within GalSim.
          </li>

          <br>

          <li>  Go check out the alpha version: <a href="https://github.com/McWilliamsCenter/galsim_hub">https://github.com/McWilliamsCenter/galsim_hub</a>
          </li>

        </ul>

      </div>
      </div>

    </div>
    </div>



  </section>




      <section>
      	<h2> Hybrid physics-ML models for image inverse problems</h2>


                  <br>
                  <br>

                  <hr>
                  <br>
                  <br>
                  <div align="left" style="margin-left: 20px;">
                  <h3>Work in collaboration with <br>
                  Peter Melchior, Fred Moolekamp, Remy Joseph</h3>
                  </div>


                  <br>
                  <br>

                  <div style="float:center; font-size: 25px"><b>Lanusse</b>, Melchior, Moolekamp (2019)<br>
                   </div>


      </section>

      <section>
      <section data-background="/talks/assets/gal_hsc.png">

      </section>
 				<section>
 					<h3 class="slide-title">The challenge of galaxy blending</h3>
							<div class="container">
									<div class="col">
										<div style="position:relative; width:480px; height:500px; margin:0 auto;">
											<img class="fragment current-visible plain"  data-src="/talks/assets/hsc_deblending_success.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
											<img class="fragment plain" data-src="/talks/assets/hsc_shredded.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
										</div>
										<div class="fragment" data-fragment-index="0" style="float:left; font-size: 20px">Bosch et al. 2017</div>
									</div>
									<div class="col">
									<ul>
										<li class="fragment fade-up" data-fragment-index="0"> In HSC over 60% of all galaxies are blended</li>
										<br>
										<li class="fragment fade-up" data-fragment-index="0"> Important impact on our main cosmological probes</li>
										<br>
										<li class="fragment fade-up" data-fragment-index="1"> Current generation of deblenders does not meet our target requirements</li>
										<br>
										<ul class="fragment fade-up" data-fragment-index="2">
											<li> Existing methods rely on simple assumptions about galaxy profiles, like <i>symmetry</i> or <i>monotonicity</i></li>
										</ul>
									</ul>
									</div>
							</div>

							<div class="fragment fade-up"data-fragment-index="3" >
								Deblending is an ill-posed inverse problem, akin to <i>Blind Source Separation</i>. The is no <b>single solution</b>.<br>
								$\Longrightarrow$ Intuitively, the key will to leverage an understanding of how individual <i>galaxies look like</i>.
							</div>
 				</section>
				</section>

				<section>
					<section>
					<h3 class="slide-title">Deep Learning applied to deblending (Reiman & Gohre 2018)</h3>
								<div>
								<img class="plain" data-src="/talks/assets/Reiman2018_1.png" />
									Branched GAN model for deblending
								</div>

							<div class="block fragment">
								<div class="block-title">
									The issue with <i>black-box</i> models
								</div>
								<div class="block-content">
									<ul>
										<li> No explicit control of noise, PSF, depth, number of sources.
												<ul>
													<li> Model would have to be retrained for all observing configurations
													</li>
												</ul>
										</li>
										<br>
										<li> No guarantees on the network output (e.g. flux preservation, artifacts)
										</li>
									</ul>
							</div>
						</div>
					</section>

					<section>
								<img class="plain" data-src="/talks/assets/Reiman2018_2.png"/>
					</section>
				</section>

				<section>
				<section>
					<h3 class="slide-title">Linear inverse problems</h3>

					$\boxed{y =  \mathbf{A}x + n}$
					<br>
					<br>
					$\mathbf{A}$ is known and encodes our physical understanding of the problem.
					<span class="fragment"><br>$\Longrightarrow$ When non-invertible or ill-conditioned, the inverse problem is ill-posed with no unique solution $x$</span>
					<div class="container fragment fade-up">
							<div class="col">
								<img data-src="/talks/assets/pluto_smooth.png" class="plain"></img>
								Deconvolution
							</div>
							<div class="col">
								<img data-src="/talks/assets/pluto_missing.png" class="plain"></img>
								Inpainting
							</div>
							<div class="col">
								<img data-src="/talks/assets/plutoNoise.png" class="plain"></img>
								Denoising
							</div>
					</div>

				</section>

				<section data-vertical-align-top>
					$\boxed{y =  \mathbf{A}x + n}$
					<br>
					<br>
					The Bayesian view of the problem:
					<br>
					<br>
					$$ p(x | y) \propto p(y | x) \ p(x) $$
					<br>

					<ul>
						<li class="fragment fade-up">$p(y | x)$ is the data likelihood, which <b>contains the physics</b><br>
						</li>
						<br>
						<li class="fragment fade-up">$p(x)$ is our prior knowledge on the solution.</li>
					</ul>
					<br>
					<br>
					<div class="fragment fade-up">
					With these concepts in hand, we want to estimate the Maximum A Posteriori solution:
					<br>
					<br>
					$$\hat{x} = \arg\max\limits_x \ \log p(y \ | \ x)  + \log p(x)$$
					<br>
					For instance, if $n$ is Gaussian, $\hat{x} = \arg\max\limits_x \ \frac{1}{2} \parallel y - \mathbf{A} x \parallel_{\mathbf{\Sigma}}^2 + \log p(x)$
					</div>
					<br>
					<div class="fragment fade-up">
						<h3>How do you choose the prior ?</h3>
					</div>
				</section>

				<section>
					<h3 class="slide-title"> Classical examples of signal priors </h3>
						<div class="container">
							<div class="col">
								Sparse
								<img data-src="/talks/assets/wavelet.png" height="400" class="plain"></img><br>
								$$ \log p(x) = \parallel \mathbf{W} x \parallel_1 $$
							</div>
							<div class="col">
								Gaussian
								<img data-src="/talks/assets/zknj8.jpg" height="400" class="plain"></img>
								$$ \log p(x) = x^t \mathbf{\Sigma^{-1}} x $$
							</div>
							<div class="col">
								Total Variation
								<img data-src="/talks/assets/shepp-Logan.ppm" class="plain"></img>
								$$ \log p(x) = \parallel \nabla x \parallel_1 $$

							</div>
					</div>
				</section>

				<section data-background="/talks/assets/hsc_screen.png">
						<h2>But what about this?</h2>

				</section>
			</section>

			<section class="inverted" data-background="#000">
				<h2>
				Can we use Deep Learning to learn the prior from data?</h2>
			</section>

			<section>
				<h3 class="slide-title" >A deblending toy example</h3>
				<div class="container">
				<div class="col">
						<div class="fig-container" data-file="dgm_prior.html" data-style="height: 550px;"></div>
						<br>
						Try me out at: <a href="https://eiffl.github.io/DeepPriors">https://eiffl.github.io/DeepPriors</a>
				</div>

			 <div class="col">
				 <ul>
					 <li>Assume a blend with two components $x_1$ and $x_2$ <br> $x_1 + x_2$ must match the data $y$</li>
					 <br>
					 <li>Each component of the blend should lie on the "realistic galaxy manifold", symbolized by the two-moons distribution.</li>
				 </ul>
				 <p> We are solving: </p>
					 $\arg \max - \frac{1}{2} \parallel {\color{Orchid} y} - {\color{red} \sum_{\color{red} i} {\color{red} x}_{\color{red} i}} \parallel_2^2 + \log p({\color{SkyBlue} x_{\color{SkyBlue} 1}}) + \log p({\color{GreenYellow} x_{\color{GreenYellow} 2}}) $
					 <br>
					 <br>
					 This can be done by gradient descent as long  as one has access to $\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x\color{orange})}{\color{orange} d \color{orange}x}$.
		 	 </div>
	 </div>
		</section>
			<section data-vertical-align-top>
				<h3 class="slide-title" >Not all generative models are created equal</h3>
							<img data-src="/talks/assets/generative_models_table.png" class="plain"></img>
		 						<div style="float:right; font-size: 20px">Grathwohl et al. 2018</div>
					<br>
					<br>
				<ul>
					<li> GANs and VAEs are very common and successfull but do not fit our purposes.</li>
					<br>
					<li> We need a model which can provide explicitly $\log p(x)$.</li>
					<br>
				</ul>
			</section>

			<section>
				<h3  class="slide-title">PixelCNN: Likelihood-based Autoregressive generative model</h3>
				<div class="container">
				<div class="col">
						Models the probability $p(x)$ of an image $x$ as:
						$$ p_{\theta}(x) = \prod_{i=0}^{n} p_{\theta}(x_i | x_{i-1} \ldots x_0) $$
						<ul>
								<li>Some of the best log-likelihoods on the market.</li>
								<li>Extremely stable during training.</li>
								<li>Slow to sample from.</li>
						</ul>
						<br>
						<br>

						<div class="fragment fade-up">
							<img data-src="/talks/assets/speedup.gif" class="plain"></img>
							<br>
			 				<div style="float:left; font-size: 20px">Ramachandran et al. 2017</div>
						</div>

				</div>

				<div class="col">
						<img data-src="/talks/assets/pixel_cnn_conv.png" class="plain"></img>
		 				<div style="float:right; font-size: 20px">van den Oord et al. 2016</div>
				</div>
			 </div>
			</section>

			<section>
				<h3 class="slide-title"> The Scarlet algorithm: deblending as an optimization problem</h3>
						<div style="float:right; font-size: 20px">Melchior et al. 2018</div>

						$$ \mathcal{L} = \frac{1}{2} \parallel \mathbf{\Sigma}^{-1/2} (\ Y - P \ast A S \ ) \parallel_2^2 - \sum_{i=1}^K \log p_{\theta}(S_i) + \sum_{i=1}^K g_i(A_i) +  \sum_{i=1}^K f_i(S_i)$$

				<div class="container">
				<div class="col">
						<img data-src="/talks/assets/scarlet_data.png" height=450 class="plain"></img>
				</div>

				<div class="col">

					Where for a $K$ component blend:
					<br>
						<ul>
						<li>$P$ is the convolution with the instrumental response</li>
						<br>
						<li>$A_i$ are channel-wise galaxy SEDs, $S_i$ are the morphology models</li>
						<br>
						<li>$\mathbf{\Sigma}$ is the noise covariance</li>
						<br>
						<li>$\log p_\theta$ is a PixelCNN prior</li>
						<br>
						<li>$f_i$ and $g_i$ are arbitrary additional non-smooth consraints, e.g. positivity, monotonicity...</li>
						</ul>
				</div>
			</div>

			<span class="fragment fade-up">$\Longrightarrow$ Explicit physical modeling of the observed sky</span>
			</section>

			 <section>
				<h3  class="slide-title">Training the morphology prior</h3>

				<div class="container">
					<div class="col">
						<img data-src="/talks/assets/cosmos_training.png" height=450 class="plain"></img>
						<div> Postage stamps of isolated COSMOS galaxies used for training, at WFIRST resolution and fixed fiducial PSF</div>
				</div>

				<div class="col">
				<div class="container fragment fade-in">
					<div class="col">
						isolated galaxy
					<img data-src="/talks/assets/gal_1.png" class="plain"></img>
					<span> $\log p_\theta(x) = 3293.7$ </span>
				</div>

					<div class="col">
						artificial blend
					<img data-src="/talks/assets/gal_2.png" class="plain"></img>
					<span> $\log p_\theta(x) = 3100.5 $ </span>
				</div>
					</div>
				</div>
			</section>

			<section>
				<section>
				<h3 class="slide-title">Scarlet in action</h3>

				<div class="container">
					<div class="col">
						Input blend
					<div style="position:relative; width:480px; height:480px; margin:0 auto;">
					<img data-src="/talks/assets/scar_input.png" class="plain"></img>
				</div>
					</div>

				<div class="col">
					<span class="fragment" data-fragment-index="0">Solution</span>
					<div style="position:relative; width:480px; height:480px; margin:0 auto;">
							  <img class="fragment current-visible plain" data-src="/talks/assets/old_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
							  <img class="fragment  plain" data-src="/talks/assets/pix_rec.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
					</div>
				</div>

				<div class="col">
					<span class="fragment" data-fragment-index="0">Residuals</span>
					<div style="position:relative; width:480px; height:480px; margin:0 auto;">
							  <img class="fragment current-visible plain" data-src="/talks/assets/old_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
							  <img class="fragment  plain" data-src="/talks/assets/pix_res.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
					</div>
				</div>
				</div>

				<ul>
						<li class="fragment fade-up" data-fragment-index="0">Classic priors (monotonicity, symmetry).</li>
						<br>

						<li class="fragment fade-up" data-fragment-index="1">Deep Morphology prior.</li>
				</ul>

			</section>
			<section>
				<div class="container">
					<div class="col">
						True Galaxy
					<img data-src="/talks/assets/true_input.png" class="plain"></img>
				</div>

				<div class="col">
					Deep Morphology Prior Solution

								<img class=" plain" data-src="/talks/assets/pix_rec2.png"  />

				</div>

				<div class="col">
					Monotonicity + Symmetry Solution
								<img class=" plain" data-src="/talks/assets/scar_rec2.png" />
					</div>
				</div>
			</section>
			</section>


      <section>
				<h3 class="slide-title"> Extending to multi-band images</h3>

						<img class=" plain" data-src="/talks/assets/scarlet_hsc.png" />

      </section>


			<section>
				<h3 class="slide-title"> Takeaway message</h3>

				<br>

        <ul>
          <li> We have introduce an <b class="alert">hybrid physical/deep learning model for inverse problems</b>
            <ul>
              <br>
              <li class="fragment"> Incorporate prior astrophysical knowledge as a data-driven prior
              </li>
              <br>

              <li class="fragment"> Interpretable in terms of physical components of the astronomical scene
              </li>
              <br>

              <li class="fragment"> Can accomodate different observing conditions and instruments
                <br> $\Longrightarrow$ For instance, for the joint modeling of  LSST/Euclid data
              </li>
            </ul>
          </li>

          <br>
          <br>

          <li class="fragment"> We are now in the process of evaluating the benefits of the approach compared to standard scarlet.
            Some potential complications:
            <ul>
              <li> Accounting for color gradients in this new model
              </li>
              <br>
              <li> Evaluating prior-induced biases on lensing related quantities.
              </li>
            </ul>


          </li>

        </ul>

			</section>



      				<section>
      					<h1> Conclusion </h1>
      				</section>


      						<section>
      							<h3 class="slide-title"> Conclusion </h3>

      													<div class="block ">
      														<div class="block-title">
                                    How can Deep Generative Models help us make sense of increasingly complex images ?
      														</div>
      														<div class="block-content">
                                    <br>
      															<ul>
      																<li class="fragment"> Produce more <b>realistic image simulations</b> using data-driven models
      																	<ul>
      																		<li>Essential tool for validating/calibrating pipelines</il>
      																	</ul>
      																</il>
      																<br>

      																<li class="fragment"> Provide <b>data-driven priors</b> for imaging inverse problems
      																	<ul>
      																		<li> Application to deblending, but also deconvolution, inpainting, anomaly detecion.</li>
      																	</ul>
      																</li>
      																<br>
      															</ul>
      													</div>
      												</div>

      													<br>
      										<div class="fragment">
      												<u>Advertisement:</u>
                              <br>
      												<br>
      													<ul>
      														<li> <a href="https://github.com/ml4astro/galaxy2galaxy">Galaxy2Galaxy (github.com/ml4astro/galaxy2galaxy)</a>: Repository of models and datasets for accelerating research in ML for astro.
      														</li>

      														<br>

      														<li> <a href="https://gitter.im/ml4astro/GalaxyEmulationTaskForce">Galaxy Emulation Task Force (gitter.im/ml4astro/GalaxyEmulationTaskForce)</a>: Group of people working on applications of generative models to the study of galaxies, join the conversation :-) .
      														</li>

      													</ul>
      												</div>

      													<br>
      												<p class="fragment">Thank you ! </p>
      																		 <br> <br>


      						</section>


			</div>
		</div>


    		<style>
    		/* .reveal .slides {
    		    border: 5px solid red;
    		    min-height: 100%;
    		    width: 128mm;
    		    height: 96mm;
    		} */

    		.reveal .block {
    			background-color: #191919;
    			margin-left: 20px;
    			margin-right: 20px;
    			text-align: left;
    			padding-bottom: 0.1em;
    		}

    		.reveal .block-title {
    			background-color: #333333;
    			padding:8px 35px 8px 14px;
      		color: #FFAA7F;
      		font-weight: bold;
    		}

    		.reveal .block-content {
    			padding:8px 35px 8px 14px;
    		}

    		.reveal .slide-title {
    			border-left: 5px solid white;
    			text-align: left;
    			margin-left: 20px;
    			padding-left: 20px;
    		}

    		.reveal .alert {
      		color: #FFAA7F;
      		font-weight: bold;
    		}

    		.reveal .inverted {
    			filter: invert(100%);
    		}
    /*
    	    /* .reveal .alert {
    	             padding:8px 35px 8px 14px; margin-bottom:18px;
    	             text-shadow:0 1px 0 rgba(255,255,255,1);
    	             border:5px solid #FFAA7F;
    	             -webkit-border-radius: 14px; -moz-border-radius: 14px;
    	             border-radius:14px
    	             background-position: 10px 10px;
    	             background-repeat: no-repeat;
    	             background-size: 38px;
    	             padding-left: 30px; /* 55px; if icon
    	     }
    	     .reveal .alert-block {padding-top:14px; padding-bottom:14px}
    	     .reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
    	     /*.reveal .alert li {margin-top: 1em}
    	     .reveal .alert-block p+p {margin-top:5px} */

    		</style>

		<script src="reveal.js/js/reveal.js"></script>

    <script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: false,

				//center: false,
				hash: true,

				// Visibility rule for backwards navigation arrows; "faded", "hidden"
				// or "visible"
				controlsBackArrows: 'hidden',

				// Display a presentation progress bar
				progress: true,

				// Display the page number of the current slide
				slideNumber: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// The "normal" size of the presentation, aspect ratio will be preserved
				// when the presentation is scaled to fit different resolutions. Can be
				// specified using percentage units.
				width: 1280,
				height: 720,

				// Factor of the display size that should remain empty around the content
				margin: 0.1,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 1.5,

				dependencies: [
					{ src: 'reveal.js/plugin/markdown/marked.js' },
					{ src: 'reveal.js/plugin/markdown/markdown.js' },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true },
					{ src: 'reveal.js/plugin/math/math.js', async: true },
					{ src: 'reveal.js/plugin/reveal.js-d3/reveald3.js' },
					{ src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js' },
					{ src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js' },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true }
				]

			});
		</script>
	</body>
</html>

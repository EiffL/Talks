<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Merging Physical Models with Deep Learning for Cosmology</title>

	<meta name="description" content="Learning to Discover, April 29th 2022">
	<link rel="stylesheet" href="reveal.js/dist/reset.css">
	<link rel="stylesheet" href="reveal.js/dist/reveal.css">
	<link rel="stylesheet" href="reveal.js/dist/theme/darkenergy.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section data-background-iframe="background.html">
				<div class="container">
					<div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
						<h1>Merging Physical Models with Deep Learning for Cosmology</h1>
						<h2>Learning to Discover, April 29th 2022</h2>
					</div>
				</div>
				<hr>
				<div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0);">
					<div class="container">
						<div class="col">
							<div align="left" style="margin-left: 20px;">
								<h2>François Lanusse</h2>
								<br>
								<img src="assets/CosmoStatDarkBK.png" class="plain"></img>
								<br>
							</div>
						</div>

						<div class="col">
							<br>
							<br>
							<br>
							<br>
							<img src="assets/logo_cnrs.png" class="plain" height="150"></img>
						</div>

						<div class="col">
							<br>
							<br>
							<br>
							<img src="assets/aim.png" class="plain" height="150"></img>
						</div>
					</div>
					<div> slides at <a href="https://eiffl.github.io/Paris2022">eiffl.github.io/Paris2022</a> </div>
				</div>
			</section>

					 <section data-background-image="assets/WMAP_timeline_large.jpg">
						<h3 class='slide-title' style="position:absolute;top:0;"> the $\Lambda$CDM view of the Universe </h3>
						<br> <br>
						<div class="container">
							<div class="col" style="flex: 0 0 40em;">

							</div>
							<div class="col">

								<img class="plain" data-src="assets/Euclid.png" style="width: 300px" />

								<img class="plain" data-src="assets/wfirstlogo.png" style="width: 300px" />

								<img class="plain" data-src="assets/vrro.png" style="width: 300px" />
							</div>
						</div>
						<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
					</section>

						<section>
							<section data-background-video="assets/animation-day-to-night.mov" data-background-video-muted>
								<h3 class='slide-title'>the Rubin Observatory Legacy Survey of Space and Time</h3>
								<div class="container">
									<div class="col">
										<ul>
											<li class="fragment fade-up"> 1000 images each night, 15 TB/night for 10 years</li>
											<br>
											<li class="fragment fade-up"> 18,000 square degrees, observed once every few days</li>
											<br>
											<li class="fragment fade-up"> Tens of billions of objects, each one observed $\sim1000$ times</li>
										</ul>
									</div>

									<div class="col">
										<video data-autoplay class="fragment fade-up" data-fragment-index="1" data-src="assets/obsim.mp4" type="video/mp4" />
									</div>
								</div>
							</section>

							<section data-transition="fade-in fade-out" data-background="assets/gal_sdss.png" data-vertical-align-top>
								<p>Previous generation survey: SDSS</p>
								<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
								<br> <br> <br> <br> <br> <br> <br>
								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
							</section>
							<section data-transition="fade-in fade-out" data-background="assets/gal_des.png" data-vertical-align-top>
								<p>Current generation survey: DES</p>
								<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
								<br> <br> <br> <br> <br> <br> <br>
								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
							</section>
							<section data-transition="fade-in fade-out" data-background="assets/gal_hsc.png" data-vertical-align-top>
								<p>LSST precursor survey: HSC</p>

								<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
								<br> <br> <br> <br> <br> <br> <br>
								<div style="float:right; font-size: 20px">Image credit: Peter Melchior</div>
							</section>
						</section>


									<section>
									<section class="inverted" data-background="#000">
										<h2> Can AI solve all of our problems?</h2>
									</section>

									<section>
										<h3 class="slide-title">The AI bubble</h3>

										<div class="container">
											<canvas data-chart="bar">
												<!--
													{
													 "data": {
														"labels": ["2012", "2013", "2014","2015", "2016" ,"2017", "2018", "2019", "2020", "2021"],
														"datasets": [
														 {
															"data":[ 21, 15, 17, 22, 31, 71, 113, 231, 322, 476],
															"label":"Deep Learning || CNN || Neural Network ","backgroundColor":"#A63446"
														}
														]
													 },
													 "options": { "responsive": "true",
												"scales": {
														"yAxes": [{
																"type": "linear"
														}]
												}
													}
													}
													-->
											</canvas><br>
										</div>
										<div><b>astro-ph</b> abstracts mentioning <b>Deep Learning</b>, <b>CNN</b>, or <b>Neural Networks</b></div>
									</section>

								</section>


						<section>
			        <section data-background="assets/gal_hsc.png">
								<div class="fragment">
									<div style="float:right; font-size: 20px">Branched GAN model for deblending <a href="https://arxiv.org/abs/1810.10098">(Reiman & Göhre, 2018)</a></div>

									<img class="plain" data-src="assets/Reiman2018_1.png" />
								</div>

								<div class="block fragment">
									<div class="block-title">
										The issue with using deep learning as a <i>black-box</i>
									</div>
									<div class="block-content">
										<ul>
											<li> No explicit control of noise, PSF, number of sources.
												<ul>
													<li> Model would have to be retrained for all observing configurations
													</li>
												</ul>
											</li>
											<br>
											<li class="fragment"> No guarantees on the network output (e.g. flux preservation, artifacts)
											</li>
											<br>
											<li class="fragment"> No proper uncertainty quantification.
											</li>
										</ul>
									</div>
								</div>
							</section>

							<section>
								<img class="plain" data-src="assets/Reiman2018_3.png" />
							</section>
						</section>


            <section>
              <h3 class="slide-title">Focus of this talk</h3>
              <div class=container>
                <div class="col">
                  <div class="fig-container" data-file="venn.html" data-style="height: 600px;"></div>
                </div>

                <div class="col">
                  <ul>
                    <li class="fragment">Deep Learning for astronomical data reduction</li>
                    <br>
                    <li class="fragment">Bayesian Neural Networks</li>
                    <br>
                    <li class="fragment">Physical Bayesian inference</li>
                  </ul>
                  <br>
                  <br>
                  <div class="block fragment">
                    <div class="block-title">
                      This talk
                    </div>
                    <div class="block-content">
                      Generic approach to <b>uncertainty quantification</b> and <b>interpretability</b>:
                      <br>
                      <ul>
                        <li>(Differentiable) Physical Forward Models</li>
                        <li>Deep Generative Models</li>
                        <li>Bayesian Inference</li>
                      </ul>
                    </div>
                  </div>
                </div>
              </div>
            </section>


			      <section>
			      	<h1> Data-driven priors for astronomical inverse problems</h1>
<!--
							<a href="https://arxiv.org/abs/1912.03980"><img src="https://img.shields.io/badge/astro--ph.IM-arXiv%3A1912.03980-B31B1B.svg" class="plain" style="height:25px;" /></a>
              <a href="https://www.youtube.com/watch?v=oWOU3qNHoL0"><img src="https://img.shields.io/badge/-youtube-red?logo=youtube&labelColor=grey" class="plain" style="height:25px;" /></a>
			                  <hr>
			                  <br>
			                  <div align="left" style="margin-left: 20px;">
													<div class="container">
														<div class="col">
			                  <h3>Work in collaboration with <br>
			                  Peter Melchior, Fred Moolekamp, Remy Joseph</h3>
												<br>
											</div>
											<div class="col">
											</div>
											<div class="col">
												<img data-src="assets/scarlet_data.png" style="height:450px;"/>
											</div>
											</div>
			                  </div>
			                  <br>
			                  <br> -->
			      </section>


									     <section>
									     <section>
									       <h3 class="slide-title" style="position:absolute;top:0;">A Motivating Example: Deconvolution</h3>
									       <br>
									       <br>

											  <div class="r-stack">

									        <div class="container">
									          <div class="col">
									              <img class="plain" data-src="assets/cosmos_gal.png" style="width: 250px"/>
									              <br><b class="alert">Hubble Space Telescope</b>
									          </div>

									          <div class="col fragment fade-up">
									              <img class="plain " data-src="assets/generic_network.png" style="height: 250px; width:500px"/>
									              <br>some deep neural network
									          </div>

									          <div class="col">
									            <img class="plain" data-src="assets/cosmos_gal_ground.png" style="width: 250px"/>
									            <br><b class="alert">Simulated Ground-Based Telescope</b>
									          </div>
									        </div>

													<div class="fragment"> <img class="plain" data-src="assets/galaxygan.png"> <br>
													(Schawinski, et al. 2017) </div>

												</div>

									        <br>
									        <br>
<!--
									        <div class="block fragment" >
									        <div class="block-title">
									         The issue with generic black box deep learning inference
									        </div>
									        <div class="block-content">
									            <ul>
									              <li class="fragment">No explicit control of noise, PSF, depth.
									                <ul>
									                  <li>Unless covered by the training data, the result becomes unpredictable.
									                  </li>
									                </ul>
									              </li>
									              <br>
									              <li class="fragment">No guarantees some physical properties are preserved
									                <br>$\Longrightarrow$ In this case, the flux of the deconvolved object
									              </li>
									              <br>
									              <li class="fragment"><b>Robust</b> quantification of uncertainties is extremely difficult.
									              </li>
									            </ul>
									        <br>
									      </div>
									      </div> -->

									     </section>

									     <section>
									        <h3 class="slide-title" style="position:absolute;top:0;">A Physicist's approach: let's build a model</h3>
													<div class="container">
														<div class="col">
															<div style="float:right; font-size: 20px"> <b>Lanusse</b> et al. (2020) <a href="https://arxiv.org/abs/2008.03833"><img src="https://img.shields.io/badge/astro--ph.IM-arXiv%3A2008.03833-B31B1B.svg" class="plain" style="height:25px;vertical-align:middle;" /></a></div>
														</div>
													</div>
									        <div class="container">
									          <div class="col">
									              <img class="plain fragment" data-src="assets/rand_z_square.png" style="height: 150px" data-fragment-index="4"/>
									          </div>
									          <div class="col">
									              <img class="plain fragment" data-src="assets/cosmos_gal.png" style="width: 200px" data-fragment-index="3"/>
									          </div>
									          <div class="col">
									            <img class="plain fragment" data-src="assets/cosmos_gal_psf.png" style="width: 200px" data-fragment-index="2"/>
									          </div>

									          <div class="col">
									            <img class="plain fragment" data-src="assets/cosmos_gal_pix.png" style="width: 200px" data-fragment-index="1"/>
									          </div>

									          <div class="col">
									            <img class="plain fragment" data-src="assets/cosmos_gal_ground.png" style="width: 200px" data-fragment-index="0"/>
									          </div>
									        </div>

									      <div class="container" style="position:relative; width:1000px; height:50px; margin:0 auto;">
									        <div class='col fragment' data-fragment-index='4'> <font size="10"> $\longrightarrow$ </font> <br> $g_\theta$ </div>
									        <div class='col fragment' data-fragment-index='3'> <font size="10"> $\longrightarrow$ </font> <br> PSF </div>
									        <div class='col fragment' data-fragment-index='2'> <font size="10"> $\longrightarrow$ </font> <br> Pixelation</div>
									        <div class='col fragment' data-fragment-index='1'> <font size="10"> $\longrightarrow$ </font> <br> Noise </div>
									      </div>

									      <div class="container">
									          <div class="col">
									            <div style="position:relative; width:400px; height:300px; margin:0 auto;">
									            <img data-src="assets/pgm_0.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="0"/>
									            <img data-src="assets/pgm_1.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="1"/>
									            <img data-src="assets/pgm_1.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:350px;" data-fragment-index="2"/>
									            <img data-src="assets/pgm_2.png" class="plain fragment current-visible " style="position:absolute;top:0;left:0;height:350px;" data-fragment-index="3"/>
									            <img data-src="assets/pgm_3.png" class="plain fragment " style="position:absolute;top:0;left:0;height:300px;" data-fragment-index="4"/>
									            </div>
									          </div>
									          <div class=" col">
									            <div class="block fragment" data-fragment-index="0">
									            <div class="block-title">
									             Probabilistic model
									            </div>
									            <div class="block-content">
									            <div style="position:relative; width:400px; height:100px; margin:0 auto;">
									              <div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="0"> $$ x \sim ? $$ </div>
									              <div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="1"> $$ x \sim \mathcal{N}(z, \Sigma) \quad z \sim ? $$<br>latent $z$ is a denoised galaxy image</div>
									              <div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="2"> $$ x \sim \mathcal{N}( \mathbf{P} z, \Sigma) \quad z \sim ?$$<br>latent $z$ is a super-resolved and denoised galaxy image</div>
									              <div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="3"> $$ x \sim \mathcal{N}( \mathbf{P} (\Pi \ast z), \Sigma) \quad z \sim ? $$<br>latent $z$ is a deconvolved, super-resolved, and denoised galaxy image </div>
									              <div class="plain fragment " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="4"> $$ x \sim \mathcal{N}( \mathbf{P} (\Pi \ast g_\theta(z)), \Sigma) \quad z \sim \mathcal{N}(0, \mathbf{I}) $$ <br>latent $z$ is a Gaussian sample<br> <b class="alert"> $\theta$ are parameters of the model</b> </div>
									            </div>
									            <br>
									            <br>
									            <br>
									          </div>
									          </div>
									          </div>
									      </div>
									      <div class="fragment"> $\Longrightarrow$ <b class="alert"> Decouples the morphology model from the observing conditions</b>.</div>
									     </section>

									    <section>
									      <h3 class="slide-title">Bayesian Inference a.k.a. Uncertainty Quantification</h3>
									      <div class="container">
									          <div class="col">
									            <img data-src="assets/pgm.png" class="plain" style="height: 250px;" ></img>
									          </div>
									          <div class="col">
									            The Bayesian view of the problem:
									                 $$ p(z | x ) \propto p_\theta(x | z, \Sigma, \mathbf{\Pi}) p(z)$$
									             where:
									             <br>
									               <ul>
									                 <li>$p( z | x )$ is the <b class="alert">posterior</b></li>
									                 <li>$p( x | z )$ is the data likelihood, <b class="alert">contains the physics</b></li>
									                 <li>$p( z )$ is the <b>prior</b> </li>
									               </ul>
									          </div>
									      </div>

									      <div class="container">
									          <div class="col">
									            <div style="position:relative; width:200px; height:200px; margin:0 auto;">
									              <img class="plain fragment current-visible" data-src="assets/cosmos_gal_ground.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0" />
									              <img class="plain fragment" data-src="assets/cosmos_gal.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1"/>
									            </div>
									            <div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
									              <div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;"> Data<br> $x_n$</div>
									              <div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Truth<br> $x_0$ </div>
									            </div>
									            <br>
									          </div>

									          <div class="col fragment" data-fragment-index='0' >
									            <div style="position:relative; width:200px; height:200px; margin:0 auto;">
									              <div><video data-autoplay data-loop data-src="assets/rec_samples.mp4" type="video/mp4" style="height: 200px;"/>
									              </div>
									            </div>
									            <div>Posterior samples<br> $g_\theta(z)$</div>
									          </div>

									          <div class="col">
									            <div style="position:relative; width:200px; height:200px; margin:0 auto;">
									              <div><video class="fragment current-visible" data-autoplay data-loop data-src="assets/rec_lsst.mp4" type="video/mp4" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0"/></div>
									              <img class="plain fragment " data-src="assets/rec_median.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1"/>
									            </div>

									            <div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
									              <div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;">  <br> $\mathbf{P} (\Pi \ast g_\theta(z))$</div>
									              <div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Median </div>
									            </div>
									          </div>

									          <div class="col">
									            <div style="position:relative; width:200px; height:200px; margin:0 auto;">
									              <div><video class="fragment current-visible" data-autoplay data-loop data-src="assets/res_lsst.mp4" type="video/mp4" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="0"/></div>
									              <img class="plain fragment " data-src="assets/rec_std.png" style="position:absolute;top:0;left:0;width:200px;" data-fragment-index="1"/>
									            </div>

									            <div class="container" style="position:relative; width:200px; height:50px; margin:0 auto;">
									              <div class='col fragment current-visible' data-fragment-index='0' style="position:absolute;top:0;left:0;width:200px;"> Data residuals <br> $x_n - \mathbf{P} (\Pi \ast g_\theta(z))$</div>
									              <div class='col fragment' data-fragment-index='1' style="position:absolute;top:0;left:0;width:200px;"> Standard Deviation </div>
									            </div>
									          </div>
									      </div>
									      <div class="fragment"> $\Longrightarrow$ <b class="alert">Uncertainties are fully captured by the posterior</b>.</div>
									    </section>
									  </section>

										 			  <section class="inverted" data-background="#000">
										 			    <h2>How do you do this in practice?</h2>
										 			  </section>

										 					<section>
										 			     <section>
										 			       <h3 class="slide-title">How to train your model from corrupted data</h3>
										 			       <div class="container">
										 			           <div class="col">
										 			             <img data-src="assets/pgm.png" class="plain" style="height: 300px;" ></img>
										 			           </div>
										 			           <div class="col">
										 			             <ul>
										 			               <li> Training the model amounts to <b class="alert">finding $\theta_\star$</b> that
										 			                 <b>maximizes the marginal likelihood</b> of the model:
										 			                   $$p_\theta(x | \Sigma, \Pi) = \int \mathcal{N}( \mathbf{P}(\Pi \ast g_\theta(z)), \Sigma) \ p(z) \ dz$$
										 			                   <div> $\Longrightarrow$ This is <b class="alert">classically intractable</b></div>
										 			               </li>
										 			               <br>
										 			               <li class="fragment fade-up">Efficient training of parameters $\theta$ can be achieved by:
										 			               <ul>
										 			                  <li>Adversarial Learning</li>
										 			                  <li><b class="alert">Amortized Variational Inference</b></li>
										 			               </ul>
										 			             </li>
										 			             </ul>
										 			           </div>
										 			       </div>
										 			       <div class="block fragment fade-up">
										 			       <div class="block-title">
										 			        Auto-Encoding Variational Bayes (Kingma & Welling, 2014)
										 			       </div>
										 			       <div class="block-content">
										 			         <ul>
										 			           <li class=" fade-up">We introduce a <b>parametric distribution</b> $q_\phi(z | x, \Pi, \Sigma)$ which aims to model the
										 			           posterior $p_{\theta}(z | x, \Pi, \Sigma)$.
										 			           </li>
										 			           <br>
										 			           <li class=" fade-up"> Working out the KL divergence between these two distributions leads to:

										 			             $$\log p_\theta(x | \Sigma, \Pi) \quad \geq \quad - \mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right) \quad + \quad \mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]$$

										 			             $\Longrightarrow$ <b>Evidence Lower-Bound</b>: differentiable with respect to $\theta$ and $\phi$.
										 			           </li>
										 			         </ul>
										 			     </div>
										 			     </div>
										 			     </section>

										 			     <!-- <section>
										 			     <h3 class="slide-title">The famous Variational Auto-Encoder</h3>
										 			     <img data-src="assets/vae.png" class="plain" style="height: 450px;"> </img>
										 			     <br>
										 			     <br>
										 			     $$\log p_\theta(x| \Sigma, \Pi ) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]}_{\mbox{reconstruction error}} $$
										 			     </section>

										 			     <section>
										 			          <h3 class="slide-title"> Sampling from the model</h3>
										 			             <div class="container">
										 			             <div class="col fragment fade-up">
										 			               <img data-src="assets/vae_samples_bad.png" class="plain" ></img>
										 			               Woups... what's going on?
										 			             </div>
										 			             <div class="col">
										 			               <img data-src="assets/latent_space.png" class="plain fragment fade-up" ></img>
										 			             </div>
										 			           </div>
										 			     </section>

										 			     <section>
										 			      <h3 class="slide-title"> Tradeoff between code regularization and image quality</h3>

										 			       <br>
										 			       $$\log p_\theta(x| \Sigma, \Pi ) \geq - \underbrace{\mathbb{D}_{KL}\left( q_\phi(z | x, \Sigma, \Pi) \parallel p(z) \right)}_{\mbox{code regularization}} + \underbrace{\mathbb{E}_{z \sim q_{\phi}(. | x, \Sigma, \Pi)} \left[ \log p_\theta(x | z, \Sigma, \Pi)  \right]}_{\mbox{reconstruction error}} $$

										 			       <img data-src="assets/sdss_ae_kl.png" class="plain" ></img>

										 			     </section>

										 			     <section data-background-image=https://media.giphy.com/media/3o85xIO33l7RlmLR4I/source.gif>
										 			     </section> -->
<!--
										 			     <section>
										 			       <h3 class="slide-title"> Latent space modeling with Normalizing Flows</h3>
										 			       <br>
										 			       $\Longrightarrow$ The latent space data distribution rarely match the assumed Gaussian prior.
										 			     <br>
										 			     <br>
										 			     <div class="container">
										 			     <div class="col">
										 			       <img data-src="assets/flow_dinh_1.png" class="plain fragment fade-up" data-fragment-index="1"></img>
										 			       <img data-src="assets/flow_dinh_2.png" class="plain fragment fade-up" data-fragment-index="1"></img>
										 			       <br>
										 			       <div class="fragment fade-up" style="float:right; font-size: 20px" data-fragment-index="1">Dinh et al. 2016</div>
										 			     </div>
										 			     <div class="col">
										 			               <div class="block fragment fade-up" data-fragment-index="1">
										 			               <div class="block-title">
										 			                Flow-VAE hybrid model
										 			               </div>
										 			               <div class="block-content">
										 			                 <ul>
										 			                   <li class="fragment"> We train a Normalizing Flow to learn the latent distribution
										 			                      $$ f_{\varphi} (z) \sim \int q_\phi(z|x) p(x) dx $$
										 			                   </li>
										 			                   <br>
										 			                   <li class="fragment"> We augment the generator learned by AEVB with the flow:
										 			                     $$ g^\prime  = g_\theta \circ f_\varphi $$
										 			                   </li>
										 			                 </ul>
										 			                 <br>
										 			                 <div class="fragment"> $\Longrightarrow$ Well-calibrated generative model.</div>
										 			             </div>
										 			            </div>
										 			          <br>
										 			          <br>
										 			     </div>
										 			   </div>
										 			     </section> -->

										 <section>
										 	<h3 class="slide-title"> Flow-VAE samples</h3>
										 	<br>
										 	<br>
										 	<img class="current-visible plain" data-src="assets/lanusse2020_figure1.png" />
										 </section>

										 				 </section>

										 			   <section>
										 			     <h3 class="slide-title">How to perform efficient posterior inference?</h3>
										 			     <div class="container">

										 			       <div class="col">
										 			         <img class="plain " data-src="assets/cosmos_gal_ground.png" style="height:200px;" />
										 			       </div>

										 			       <div class="col">
										 			         <div style="height:200px"><video data-autoplay data-loop data-src="assets/rec_samples.mp4" type="video/mp4" style="height: 200px;"/>
										 			         </div>
										 			       </div>
										 			       <hr style="width: 2px; height: 200px; background: white; border: none;" />
										 			       <div class="col">
										 			          <img class="fragment plain" data-fragment-index="3" data-src="assets/deep_uq_4.png" style="height:200px"/>
										 			       </div>

										 			       <div class="col">
										 			         <img class="fragment plain"  data-fragment-index="3" data-src="assets/deep_uq_contours.png"  style="height:200px"/>
										 			       </div>

										 			       <div class="col">
										 			         <img class="fragment plain"  data-fragment-index="3" data-src="assets/deep_uq_recs.png" style="height:200px" />
										 			       </div>
										 			     </div>

										 			          <div style="float:right; font-size: 20px" class="fragment" data-fragment-index="3"><a href="https://arxiv.org/abs/1910.10046">(Böhm, Lanusse, Seljak 2019)</a></div>
										 			         <ul>
										 			           <li class="fragment" data-fragment-index="1">Posterior fitting by <b class="alert">Variational Inference</b>
										 			             <br>
										 			              $$ \mathrm{ELBO} = - \mathbb{D}_{KL}\left( q_\phi(z) \parallel p(z) \right) \quad + \quad \mathbb{E}_{z \sim q_{\phi}} \left[ \log p_\theta(x_n | z, \Sigma_n, \Pi_n)  \right]$$
										 			           </li>

										 			           <li class="fragment" data-fragment-index="3">Posterior fitting by <b class="alert">$EL_{2}O$</b> <br>
										 			             $$EL_2O = \arg \min_\theta \mathbb{E}_{z \sim p^{\prime}} \sum_i \alpha_i \parallel \nabla_{z}^n \ln q_\theta(z) - \nabla_{z}^{n} \ln p(z | x_n, \Sigma_n, \Pi_n)  \parallel_2^2$$See <a href="https://arxiv.org/abs/1901.04454"> (Seljak & Yu, 2019)</a> for more details.
										 			           </li>
										 			           <br>
										 			           <li class="fragment" data-fragment-index="5">Or your favorite method...</li>
										 			         </ul>
										 			    </section>

			      <section>
			        <h3 class="slide-title">Other examples of applications of deep data-driven priors</h3>
			        <div class="container">
			          <div class="col">
			            <ul>
			              <li><em>Probabilistic Mass Mapping with Neural Score Estimation</em><br> B. Remy, <b> F. Lanusse</b>, N. Jeffrey et al. 2022<br>
			                <a href="https://arxiv.org/abs/2201.05561"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2201.05561-B31B1B.svg" class="plain" style="height:25px;" /></a>
			              </li>
			            </ul>
			            <img class=" plain" data-src="assets/cropped.gif" />
			            <br> <br>

			          </div>
			          <div class="col fragment">
			            <ul>
			              <li><em>Denoising Score-Matching for Uncertainty Quantification in Inverse Problems</em><br> Z. Ramzi, B. Remy, <b>F. Lanusse</b>, P. Ciuciu, J.L. Starck<br>
			                <a href="https://arxiv.org/abs/2011.08698"><img src="https://img.shields.io/badge/stat.ML-arXiv%3A2011.08698-B31B1B.svg" class="plain" style="height:25px;" /></a>
			              </li>
			            </ul>
			            <img class="plain" data-src="assets/knee.gif" style="height:410px;"/>
			          </div>
			        </div>
			      </section>


								<section>
									<h2>Simulation-Based Inference <br> by Neural Summarisation and Density Estimation</h2>
									<a href="https://arxiv.org/abs/2009.08459"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2009.08459-B31B1B.svg" class="plain" style="height:25px;" /></a>
									<a href="https://github.com/NiallJeffrey/Likelihood-free_DES_SV"><img src="https://badgen.net/badge/icon/github?icon=github&label" class="plain" style="height:25px;" /></a>
									<hr>
									<div class="container">
										<div class="col">
											<div align="left" style="margin-left: 20px;">
												<h3>Work in collaboration with Niall Jeffrey, Justin Alsing
												</h3>
												<img data-src="assets/niall.jpg" style='width:200px; height:200px;object-fit: cover;'></img>
												<img data-src="assets/justin.jpeg" style='width:200px; height:200px;'></img>

												<br>
												<br>
												$\Longrightarrow$ <b class="alert">Learn an implicit data likelihood</b> from simulations.
											</div>
										</div>
										<div class="col">
											<img class="plain" data-src="assets/ks_sv.png" style="width:350px;" />
										</div>
									</div>
									<br>
								</section>


					      			<section>
					      				<h3 class='slide-title'> limits of traditional cosmological inference </h3>
					      				<div class='container'>
					      					<div class='col'>
					      						<div style="position:relative; width:480px; height:30px; margin:0 auto;">
					      							<div class="fragment current-visible" style="position:absolute;top:0;" data-fragment-index="1">HSC cosmic shear power spectrum</div>
					      							<div class="fragment" style="position:absolute;top:0;" data-fragment-index="2">HSC Y1 constraints on $(S_8, \Omega_m)$</div>
					      						</div>
					      						<div style="position:relative; width:480px; height:300px; margin:0 auto;">
					      							<div class="fragment current-visible" style="position:absolute;top:0;left:0;" data-fragment-index="0">
					      								<img class="plain" data-src="assets/alonso_g1.png" />
					      								<img class="plain" data-src="assets/alonso_g2.png" />
					      							</div>
					      							<img class="fragment current-visible plain" data-src="assets/hsc_correlation_function.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
					      							<img class="fragment  plain" data-src="assets/hsc_constraints.png" style="position:absolute;top:0;left:0;" data-fragment-index="2" />
					      						</div>
					      						<div class="fragment" data-fragment-index="1" style="float:right; font-size: 20px">(Hikage et al. 2018)</div>
					      					</div>

					      					<div class='col'>
					      						<ul>
					      							<li class="fragment" data-fragment-index="0"> Measure the ellipticity $\epsilon = \epsilon_i + \gamma$ of all galaxies<br>
					      								$\Longrightarrow$ Noisy tracer of the weak lensing shear $\gamma$ </li>
					      							<br>
					      							<li class="fragment" data-fragment-index="1"> Compute <b class="alert">summary statistics</b> based on 2pt functions, <br>e.g. the <b>power spectrum</b> </li>
					      							<br>
					      							<li class="fragment" data-fragment-index="2"> Run an MCMC to recover a posterior on model parameters, using an <b class="alert">analytic likelihood</b>
					      								$$ p(\theta | x ) \propto \underbrace{p(x | \theta)}_{\mathrm{likelihood}} \ \underbrace{p(\theta)}_{\mathrm{prior}}$$
					      							</li>
					      						</ul>
					      					</div>
					      				</div>

					      				<div class="block fragment">
					      					<div class="block-title">
					      						Main limitation: the need for an explicit likelihood
					      					</div>
					      					<div class="block-content">
					      						We can only compute the likelihood for <b class="alert">simple summary statistics</b> and on <b class="alert">large scales</b>
					      						<br>
					      						<br>
					      						<div class="fragment"> $\Longrightarrow$ We are dismissing a large amount of information! </div>
					      					</div>
					      				</div>
					      			</section>

					            <section>
					  						<h3 class='slide-title'>A different road: forward modeling</h3>

					  						<div class='container'>
					  							<div class='col'>
					  								<ul>
					  									<li> Instead of trying to analytically evaluate the likelihood,
					  										let us build a forward model of the observables.</li>
					  									<br>
					  								</ul>
					  								<br>
					  								<br>
					  								<br>
					  								<div class="fragment">
					  									$\Longrightarrow$ Learn an <b>implicit likelihood</b> $p(x|\theta)$ given by the <b class="alert">simulator as our physical model</b>
					  								</div>
					  								<br>
					  								<br>
					  								<br>
					  								<br>
					  							</div>

					  							<div class='col'>

					  								<div style="position:relative; width:600px; height:600px; margin:0 auto;">
					  									<img class="plain" data-src="assets/forward_model.png" style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="0" />
					  								</div>
					  							</div>
					  						</div>
					  					</section>

					      			<section>
					      				<section>
					      					<h3 class="slide-title">End-to-end framework for likelihood-free parameter inference with DES SV</h3>
					      					<div class="container">
					      						<div class="col">
					      							<div style="float:right; font-size: 20px"> Jeffrey, Alsing, <b>Lanusse</b> (2021) <a href="https://arxiv.org/abs/2009.08459"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2009.08459-B31B1B.svg" class="plain"
					      										style="height:25px;vertical-align:middle;" /></a></div>
					      						</div>
					      					</div>

					      					<div class="container">
					      						<div class="col">
					      							<img class="plain" data-src="assets/ks_sv.png" style="height:550px;"></img>
					      						</div>

					      						<div class="col fragment">
					      							<img class="plain" data-src="assets/orthant.png" style="height:300px;" />
					      							<img class="plain" data-src="assets/sim_params.png" style="height:300px;" /><br>
					      							Suite of N-body + raytracing simulations: $\mathcal{D}$
					      						</div>
					      					</div>
					      				</section>

												<section>
													<h3>Our strategy</h3>
													<div class="block fragment">
														<div class="block-title">
															A two-steps approach to inference
														</div>
														<div class="block-content">
															<ul>
																<li> Automatically learn an <b>optimal low-dimensional summary statistic</b>
																	$$y = f_\varphi(\kappa_{KS}) $$
																</li>

																<br>

																<li class="fragment"> Use Neural Density Estimation to build an <b>estimate $p_\phi$ of the likelihood function $p(y \ | \ \theta)$</b> (Neural Likelihood Estimation)
																</li>

																<br>

																<li class="fragment"> Run a conventional Markov Chain Monte Carlo sampling
																</li>

																	</ul>
																</li>
															</ul>
														</div>
													</div>
												</section>
											</section>

											<section>
					      				<section>
					      					<h3 class="slide-title">Learning summary statistics by Variational Mutual Information Maximization</h3>
					      					<br>
					      					<br>
					      					<div class="container">

					      						<div class="col">
					      							<img class="plain" data-src="assets/mutual_information.png" />
					      						</div>

					      						<div class="col">
					      							<ul>
					      								<li> Mutual information between $X$ and $Y$:
					      									<blockquote>
					      										&ldquo;"amount of information" obtained about one random variable through observing the other random variable&rdquo;
					      									</blockquote>
					      								</li>
					      								<br>
					      								<li class="fragment">Given a parametric summarizing function $y = f_\phi(\kappa(\theta))$
					      									<b class="alert">optimizing $f_\phi$ can be done by maximizing $I(y, \theta)$</b>.
					      								</li>
					      								<br>
					      								<li class="fragment">In practice, $f_\phi$ is a CNN, trained to maximize a
					      									variational lower bound on the mutual information:
					      									$$ I(y ; \theta) \ \ge \ \mathbb{E}_{y, \theta} [ \log q_\phi(\theta | y) ] + H(\Theta) $$
					      								</li>
					      							</ul>
					      						</div>
					      					</div>
					      				</section>

					      				<section>
					      					<h3 class='slide-title'> deep residual networks for lensing maps compression</h3>

					      					<div class="container">

					      						<div class="col" style="flex: 0 0 15em;">
					      							<img class="plain" data-src="assets/jeffrey_model.png" style="height:550px" /><br>
					      						</div>
					      						<div class="col">
					      							<ul>
					      								<li> Deep Residual Network $y = f_\phi(x)$ followed by neural density estimator $q_\phi(\theta | y)$
					      								</li>
					      								<br>
					      								<li class="fragment">Training on weak lensing maps simulated for different cosmologies</li>
					      								<div class="container fragment">
					      									<div class="col" style="flex: 0 0 26em;">
					      										<img class="plain" data-src="assets/mass_maps.png" /><br>
					      									</div>
					      									<div class="col">
					      										<img class="plain" data-src="assets/TF_FullColor_Horizontal.png" />
					      										<br>
					      										<br>
					      										<br>
					      										<img class="plain" data-src="assets/google-cloud-platform-logo.png" />
					      									</div>
					      								</div>
					      								<li class="fragment">Training by Variational Mutual Information Maximization:
					      									$$\mathbb{E}_{(x, \theta) \in \mathcal{D}} [ \log q_\phi(\theta | f_\phi(y) ) ]$$
					      								</li>
					      							</ul>
					      						</div>
					      					</div>
					      				</section>
											</section>

											<section>

					      				<section>
					      					<h3 class="slide-title">Estimating the likelihood by Neural Density Estimation</h3>
					      					<br>
					      					$\Longrightarrow$ We cannot assume a Gaussian likelihood for the summary $y = f_\phi(\kappa)$ but we can learn $p(y | \theta)$: Neural Likelihood Estimation.
					      					<br>
					      					<br>
					      					<div class="container">
					      						<div class="col">
					      							<img data-src="assets/flow_dinh_1.png" class="plain fragment fade-up" data-fragment-index="1"></img>
					      							<img data-src="assets/flow_dinh_2.png" class="plain fragment fade-up" data-fragment-index="1"></img>
					      							<br>
					      							<div class="fragment fade-up" style="float:right; font-size: 20px" data-fragment-index="1">Dinh et al. 2016</div>
					      						</div>
					      						<div class="col">
					      							<div class="block fragment fade-up" data-fragment-index="1">
					      								<div class="block-title">
					      									Neural Likelihood Estimation by Normalizing Flow
					      								</div>
					      								<div class="block-content">
					      									<ul>
					      										<li> We use a conditional Normalizing Flow to build an explicit model for the likelihood function
					      											$$ \log p_\varphi (y | \theta)$$
					      										</li>
					      										<br>
					      										<li class="fragment"> In practice we use the pyDELFI package and an <b>ensemble of NDEs</b> for robustness.
					      										</li>
					      										<br>
					      										<li class="fragment"> Once learned, we can use the likelihood as part of a conventional MCMC chain</li>
					      									</ul>
					      								</div>
					      							</div>
					      							<br>
					      							<br>
					      						</div>
					      					</div>
					      				</section>

												</section>

					      				<section>
					      					<h3 class="slide-title">Parameter constraints from DES SV data</h3>

					      					<div class="container">
					      						<div class="col">
					      							<img class="plain" data-src="assets/results_jeffrey.png" />
					      						</div>

					      						<div class="col fragment">
					      							<img class="plain" data-src="assets/jeffrey_s8.png" />
					      						</div>
					      					</div>
					      				</section>



<!--

																							<section>
																								<h3 class="slide-title"> Takeaway message</h3>

																								<br>
																								<br>
																								<br>

																				        <ul>
																				          <li> We have introduce an <b class="alert">hybrid physical/deep learning model for inverse problems</b>
																				            <ul>
																				              <br>
																				              <li class="fragment"> Incorporate prior astrophysical knowledge as a data-driven prior
																				              </li>
																				              <br>

																				              <li class="fragment"> Interpretable in terms of physical components of the astronomical scene
																				              </li>
																				              <br>
																				              <br>

																				              <li class="fragment"> Can accomodate different observing conditions and instruments
																				                <br> $\Longrightarrow$ For instance, for the joint modeling of  LSST/Euclid data
																				              </li>
																				            </ul>
																				          </li>

																				          <br>
																				          <br>
																				              <br>
																								<br>

																				          <!-- <li class="fragment"> We are now in the process of evaluating the benefits of the approach compared to standard scarlet.
																				            Some potential complications:
																				            <ul>
																				              <li> Accounting for color gradients in this new model
																				              </li>
																				              <br>
																				              <li> Evaluating prior-induced biases on lensing related quantities.
																				              </li>
																				            </ul>
																				          </li>
																				        </ul>

																							</section> -->




																												<section>
																													<h1>Automatically Differentiable Physics </h1>
																												</section>

<!--
																									      					<section>
																									      						<h3 class="slide-title">the hammer behind the Deep Learning revolution: Automatic Differentation</h3>

																									      						<ul>
																									      							<li class="fragment"> <b>Automatic differentiation</b> allows you to compute analytic derivatives of arbitraty expressions:<br>
																									      								If I form the expression $y = a * x + b$, it is separated in fundamental ops:
																									      								$$ y = u + b \qquad u = a * x $$
																									      								then gradients can be obtained by the chain rule:
																									      								$$\frac{\partial y}{\partial x} = \frac{\partial y}{\partial u} \frac{ \partial u}{\partial x} = 1 \times a = a$$
																									      							</li>
																									      							<br>
																									      							<li class="fragment"> This is a fundamental tool in Machine Learning, and autodiff frameworks include TensorFlow and PyTorch.
																									      							</li>
																									      						</ul>
																									      						<br>
																									      						<br>
																									      						<div class="block fragment">
																									      							<div class="block-title">
																									      								Enters JAX: NumPy + Autograd + GPU
																									      							</div>
																									      							<div class="block-content">

																									      								<div class="container">
																									      									<div class="col">
																									      										<ul>
																									      											<li>JAX follows the NumPy api!
																									      												<pre class="python"><code data-trim data-noescape>
																									      										import jax.numpy as np
																									      									</code></pre>
																									      											</li>
																									      											<li>Arbitrary order derivatives</li>
																									      											<li>Accelerated execution on GPU and TPU</li>

																									      										</ul>
																									      									</div>
																									      									<div class="col" align="center">

																									      										<img data-src="https://raw.githubusercontent.com/google/jax/master/images/jax_logo_250px.png" class="plain" />
																									      									</div>
																									      								</div>
																									      					</section>

																									      					<section>
																									      						<section>
																									      							<h3 class="slide-title"> jax-cosmo: Finally a differentiable cosmology library, and it's in JAX!</h3>

																									      							<div class="container">
																									      								<div class="col">
																									      									<img data-src="assets/github.png" class="plain" style="height:70px" />
																									      									<div> <a href="https://github.com/DifferentiableUniverseInitiative/jax_cosmo/">https://github.com/DifferentiableUniverseInitiative/jax_cosmo</a>
																									      									</div>

																									      									<pre class="python"><code data-trim data-noescape>
																									      										import jax.numpy as np
																									      										import jax_cosmo as jc

																									      										# Defining a Cosmology
																									      										cosmo = jc.Planck15()

																									      										# Define a redshift distribution with smail_nz(a, b, z0)
																									      										nz = jc.redshift.smail_nz(1., 2., 1.)

																									      										# Build a lensing tracer with a single redshift bin
																									      										probe = probes.WeakLensing([nz])

																									      										# Compute angular Cls for some ell
																									      										ell = np.logspace(0.1,3)
																									      										cls = angular_cl(cosmo_jax, ell, [probe])
																									      									</code></pre>

																									      									<div class="block">
																									      										<div class="block-title">
																									      											Current main features
																									      										</div>
																									      										<div class="block-content">
																									      											<ul>
																									      												<li>Weak Lensing and Number counts probes</li>
																									      												<li>Eisenstein & Hu (1998) power spectrum + halofit</li>
																									      												<li>Angular $C_\ell$ under Limber approximation </li>
																									      											</ul>
																									      											<div>$\Longrightarrow$ 3x2pt DES Y1 capable </div>
																									      										</div>
																									      									</div>

																									      								</div>

																									      								<div class="col">
																									      									<img class="plain" data-src="assets/jc_vs_ccl_lensing.png" />
																									      									<img class="plain" data-src="assets/jc_vs_ccl_clustering.png" />
																									      									<br>
																									      									Validating against the <a href="https://github.com/LSSTDESC/CCL">DESC Core Cosmology Library</a>
																									      								</div>
																									      							</div>
																									      						</section>

																									      						<section>
																									      							<h3 class="slide-title"> let's compute a Fisher matrix</h3>

																									      							<br>

																									      							$$F = - \mathbb{E}_{p(x | \theta)}[ H_\theta(\log p(x| \theta)) ] $$

																									      							<br>

																									      							<div class="container">
																									      								<div class="col fragment">

																									      									<pre class="python"><code data-trim data-noescape>
																									      					import jax
																									      					import jax.numpy as np
																									      					import jax_cosmo as jc

																									      					# .... define probes, and load a data vector

																									      					def gaussian_likelihood( theta ):
																									      					  # Build the cosmology for given parameters
																									      					  cosmo = jc.Planck15(Omega_c=theta[0], sigma8=theta[1])

																									      					  # Compute mean and covariance
																									      					  mu, cov = jc.angular_cl.gaussian_cl_covariance_and_mean(cosmo,
																									      					                                                    ell, probes)
																									      					  # returns likelihood of data under model
																									      					  return jc.likelihood.gaussian_likelihood(data, mu, cov)

																									      					# Fisher matrix in just one line:
																									      					F = - jax.hessian(gaussian_likelihood)(theta)
																									      					</code></pre>
																									      									<a href="https://colab.research.google.com/github/DifferentiableUniverseInitiative/jax_cosmo/blob/master/docs/notebooks/jax-cosmo-intro.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg"
																									      											alt="Open In Colab" class="plain" style="height:25px;" /></a>
																									      								</div>

																									      								<div class="col fragment">
																									      									<img data-src="assets/Fisher_mat.png" class="plain"><br><br>
																									      								</div>
																									      							</div>

																									      							<ul>
																									      								<li class="fragment"> <b class="alert">No derivatives were harmed by finite differences in the computation of this Fisher!</b> </li>
																									      								<li class="fragment"> Only a small additional compute time compared to one forward evaluation of the model</li>
																									      							</ul>

																									      						</section>


																																		      					<section>
																																		      						<h3 class="slide-title"> Inference becomes fast and scalable</h3>

																																		      						<div class="container">
																																		      							<div class="col">

																																		      								<ul>
																																		      									<li>Current cosmological MCMC chains take <b>days</b>, and typically require access
																																		      										to large computer clusters.</li>
																																		      									<br>
																																		      									<li class="fragment" data-fragment-index="1"><b class="alert">Gradients of the log posterior are required for modern efficient and scalable inference</b> techniques:
																																		      										<ul>
																																		      											<li>Variational Inference</li>
																																		      											<li>Hamiltonian Monte-Carlo</li>
																																		      										</ul>
																																		      									</li>
																																		      									<br>
																																		      									<li class="fragment" data-fragment-index="2">In jax-cosmo, we can trivially obtain <b>exact</b> gradients:
																																		      										<pre class="python"><code data-trim data-noescape>
																																		      					def log_posterior( theta ):
																																		      					    return gaussian_likelihood( theta ) + log_prior(theta)

																																		      					score = jax.grad(log_posterior)(theta)
																																		      					</code></pre>
																																		      									</li>

																																		      									<br>
																																		      									<li class="fragment" data-fragment-index="3">On a DES Y1 analysis, we find convergence in 70,000 samples with vanilla HMC, 140,000 with Metropolis-Hastings</li>
																																		      								</ul>

																																		      							</div>

																																		      							<div class="col">
																																		      								<div class="fragment" data-fragment-index="3">
																																		      									<img data-src="assets/jc_3x2pt_hmc.png" class="plain" /><br>
																																		      									DES Y1 posterior, jax-cosmo HMC vs Cobaya MH <br>(credit: Joe Zuntz)
																																		      								</div>
																																		      							</div>
																																		      						</div>
																																		      					</section>
																									      					</section>


																									      					<section>
																																		<section>
																																			<h3 class="slide-title">LSST DESC 3x2pt Tomography Challenge</h3>
																																			<div class="container">
																																				<div class="col">
																																					<div style="float:right; font-size: 20px"> Zuntz, <b>Lanusse</b>, et al. (2021)
																																						<a href="https://arxiv.org/abs/2108.13418"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2008.13418-B31B1B.svg" class="plain" style="height:25px;vertical-align:middle;" /></a>
																																					</div>
																																				</div>
																																			</div>
																																			<div class="block">
																																				<div class="block-title">
																																					Description of the challenge
																																				</div>
																																				<div class="block-content">
																																					<blockquote>
																																						&ldquo;Given (g)riz photometry, find a tomographic bin assignment
																																						method that optimizes a 3x2pt analysis.&rdquo;
																																					</blockquote>
																																					<ul>
																																						<li> Metrics: Total Signal-to-Noise: $m_{SNR} = \sqrt{\mu^t \mathbf{C}^{-1} \mu}$ ; <b class="alert">DETF Figure of Merit</b>: $m_{FOM} = \frac{1}{\sqrt{ \det(\mathbf{F}^{-1})}}$
																																						</li>
																																						<li> Idealized setting: assumes perfect training set. More info at: <a href="https://github.com/LSSTDESC/tomo_challenge">https://github.com/LSSTDESC/tomo_challenge</a>
																																						</li>
																																					</ul>
																																				</div>
																																			</div>

																																			<div class="container">
																																				<div class="col">
																																					<img class="plain fragment" data-src="assets/nnexample.png" data-fragment-index="1" />
																																				</div>

																																				<div class="col">
																																					<ul>
																																						<li class="fragment" data-fragment-index="0"> <b>Conventional strategy</b>: Use a photoz code to estimate redshifts,
																																							then bin galaxies based on their photoz.
																																						</li>
																																						<br>
																																						<li class="fragment" data-fragment-index="1"> <b class="alert">Strategy with Differentiable Physics</b>:
																																							<ul>
																																								<li> Introduce a parametric bin assignement function $f_\theta(x_{phot})$</li>
																																								<li> Optimize $\theta$ by back-propagating through the challenge metrics. </li>
																																						</li>

																																					</ul>
																																				</div>
																																			</div>
																																		</section>

																									      						<section>
																									      						<iframe width="100%" height="849" frameborder="0"
																									      						  src="https://observablehq.com/embed/@eiffl/tomo-challenge-results-visualization?cells=viewof+results_bands%2Cmain_plot"></iframe>
																									      						</section>
																									      					</section> -->

																																	<section>
																																		<h3 class='slide-title'>Back to forward modeling: the Hierarchical Bayesian Inference perspective</h3>

																																		<div class='container'>
																																			<div class='col'>
																																				<ul>
																																					<li> Another approach to using simulations is to consider them as large <b class="alert">Hierarchical Bayesian Models</b>.</li>
																																					<br>
																																					<li class="fragment" data-fragment-index="1"> Each component of the model is now tractable, but at the
																																						cost of a <b>large number of latent variables</b>.
																																					</li>
																																				</ul>

																																				<br>
																																				<div class="fragment">
																																					$\Longrightarrow$ How to peform efficient inference in this large number of dimensions?
																																				</div>
																																				<br>
																																				<br>
																																				<ul class="fragment"> A non-exhaustive list of methods:
																																					<li> Hamiltonian Monte-Carlo
																																					</li>
																																					<li> Variational Inference
																																					</li>
																																					<li> MAP+Laplace
																																					</li>
																																					<li> Gold Mining
																																					</li>
																																					<li> Dimensionality reduction by Fisher-Information Maximization
																																					</li>
																																				</ul>
																																				<br>
																																				<br>
																																				<div class="fragment">
																																					What do they all have in common?<br>
																																					-> They require fast, accurate, <b class="alert">differentiable</b> forward simulations
																																				</div>
																																			</div>

																																			<div class='col'>

																																				<div style="position:relative; width:600px; height:600px; margin:0 auto;">
																																					<img class="fragment current-visible plain" data-src="assets/forward_model.png" style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="0" />
																																					<img class="fragment plain" data-src="assets/pgm_lensing.png" style="position:absolute;top:0;left:0;width:500px;" data-fragment-index="1" />
																																					<div class="fragment" data-fragment-index="1" style="float:right; font-size: 20px">(Schneider et al. 2015)</div>
																																				</div>
																																			</div>
																																		</div>
																																	</section>


																																				<section class="inverted" data-background="#000">
																																					<h2>How do we simulate the Universe in a fast and differentiable way?</h2>
																																				</section>

																																				<section>
																																					<h3 class='slide-title'>Forward Models in Cosmology</h3>
																																					<div class="container">
																																						<div class='col'>
																																							<img data-src="assets/fieldinit.png" class="plain" style="height:300px;" />
																																							<b class="alert"> Linear Field </b>
																																						</div>
																																						<div class='col fragment' data-fragment-index='2'>
																																							<img data-src="assets/fieldfin.png" class="plain " style="height:300px;" />
																																							<b class="alert"> Final Dark Matter </b>
																																						</div>
																																						<hr style="width: 1px; height: 400px; background: white; border: none;" />
																																						<div class='col fragment' data-fragment-index='3'>
																																							<img data-src="assets/fieldhalo.png" class="plain " style="height:300px;" />
																																							<b class="alert"> Dark Matter Halos </b>
																																						</div>
																																						<div class='col fragment' data-fragment-index='4'>
																																							<img data-src="assets/fieldgal.png" class="plain " style="height:300px;" />
																																							<b class="alert"> Galaxies </b>
																																						</div>
																																					</div>
																																					<div class="container" style="position:relative; width:1000px; height:50px; margin:0 auto;">
																																						<div class='col fragment' data-fragment-index='2'>
																																							<font size="10"> $\longrightarrow$ </font> <br>
																																							<div class="fragment grow" data-fragment-index='5'>N-body simulations </div>
																																						</div>
																																						<div class='col fragment' data-fragment-index='3'>
																																							<font size="10"> $\longrightarrow$ </font> <br> Group Finding <br> algorithms
																																						</div>
																																						<div class='col fragment' data-fragment-index='4'>
																																							<font size="10"> $\longrightarrow$ </font> <br> Semi-analytic &amp <br> distribution models
																																						</div>
																																						<!-- 		<div class='fragment' data-fragment-index='2'> N-body simulations <div> -->
																																						<!-- <div class='fragment' data-fragment-index='3'> Group Finding algorithms <div> -->
																																						<!-- <div class='fragment' data-fragment-index='4'> Semi-analytic models <div> -->
																																					</div>
																																				</section>

																																				<section>
																																					<h3 class='slide-title'>You can try to learn the simulation...</h3>
																																					<div style="float:right; font-size: 25px">Learning particle displacement with a UNet. S. He, et al. (2019)</div><br><br>

																																					<img data-src="assets/Model-Comparison.jpg" style="height:400px;" />

																																					<div class="block fragment">
																																						<div class="block-title">
																																							The issue with using deep learning as a <i>black-box</i>
																																						</div>
																																						<div class="block-content">
																																							<ul>
																																								<li> No guarantees to work outside of training regime.
																																								</li>
																																								<li> No guarantees to capture dependence on cosmology accurately.
																																								</li>
																																							</ul>
																																						</div>
																																					</div>
																																				</section>

																																				<section>
																																					<h3 class='slide-title'>the Fast Particle-Mesh scheme for N-body simulations</h3>
																																					<b>The idea</b>: approximate gravitational forces by estimating densities on a grid.

																																					<div class='container'>
																																						<div class='col'>
																																							<ul>
																																								<li>The numerical scheme:
																																									<br>
																																									<br>
																																									<ul>
																																										<li class="fragment" data-fragment-index="1"> Estimate the density of particles on a mesh<br>
																																											=> compute gravitational forces by FFT
																																										</li>

																																										<br>

																																										<li class="fragment" data-fragment-index="2"> Interpolate forces at particle positions
																																										</li>

																																										<br>

																																										<li class="fragment" data-fragment-index="3"> Update particle velocity and positions, and iterate
																																										</li>
																																									</ul>
																																								</li>
																																								<br>

																																								<li class='fragment'> Fast and simple, at the cost of approximating short range interactions.
																																								</li>

																																							</ul>
																																						</div>

																																						<div class='col'>

																																							<div style="position:relative; width:550px; height:550px; margin:0 auto;">
																																								<img class="fragment current-visible plain" data-src="assets/particle_positions_0.png" style="position:absolute;top:0;left:0;" data-fragment-index="0" />
																																								<img class="fragment current-visible plain" data-src="assets/particle_density_0.png" style="position:absolute;top:0;left:0;" data-fragment-index="1" />
																																								<img class="fragment current-visible plain" data-src="assets/particle_positions_0.png" style="position:absolute;top:0;left:0;" data-fragment-index="2" />
																																								<img class="fragment  plain" data-src="assets/particle_positions_1.png" style="position:absolute;top:0;left:0;" data-fragment-index="3" />

																																							</div>

																																						</div>
																																					</div>

																																					<div class="fragment"> $\Longrightarrow$ Only a series of FFTs and interpolations.</div>
																																				</section>


																																		<section>
																									      					<section>
																									      							<h3 class='slide-title'>introducing FlowPM: Particle-Mesh Simulations in TensorFlow</h3>
																									      							<div class="container">
																									      								<div class="col">
																									      									<div style="float:right; font-size: 20px"> Modi, <b>Lanusse</b>, Seljak (2020)
																									      										<a href="https://arxiv.org/abs/2010.11847"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2010.11847-B31B1B.svg" class="plain" style="height:25px;vertical-align:middle;" /></a></div>
																									      								</div>
																									      							</div>
																									      							<div class='container'>
																									      								<div class='col'>
																									      									<img data-src="assets/github.png" class="plain" style="height:70px" />
																									      									<img data-src="assets/TF_FullColor_Horizontal.png" class='plain' style="height: 70px;" />

																									      									<div> <a href="https://github.com/DifferentiableUniverseInitiative/flowpm">https://github.com/DifferentiableUniverseInitiative/flowpm</a>
																									      									</div>
																									      									<pre class="python"><code data-trim data-noescape>
																									      													import tensorflow as tf
																									      													import flowpm
																									      													# Defines integration steps
																									      													stages = np.linspace(0.1, 1.0, 10, endpoint=True)

																									      													initial_conds = flowpm.linear_field(32,       # size of the cube
																									      													                                   100,       # Physical size
																									      													                                   ipklin,    # Initial powerspectrum
																									      													                                   batch_size=16)

																									      													# Sample particles and displace them by LPT
																									      													state = flowpm.lpt_init(initial_conds, a0=0.1)

																									      													# Evolve particles down to z=0
																									      													final_state = flowpm.nbody(state, stages, 32)

																									      													# Retrieve final density field
																									      													final_field = flowpm.cic_paint(tf.zeros_like(initial_conditions),
																									      													                               final_state[0])
																									      												</code></pre>
																									      									<ul>
																									      										<li> Readily automatically differentiable
																									      										</li>
																									      										<li> Seamless interfacing with deep learning components
																									      										</li>
																									      									</ul>
																									      									<br>
																									      									<br>
																									      									<br>
																									      									<br>
																									      									<br>
																									      								</div>

																									      								<div class='col'>
																																					<!-- <img data-src="assets/flowpm.gif"></img> -->
																									      									<div class="fig-container" data-file="flowpm_16.html" data-style="height: 550px;"></div>
																									      									<br>
																									      									<br>
																									      									<br>
																									      									<br>
																									      								</div>
																									      							</div>
																									      						</section>

																																		<section>
																																			<h3 class='slide-title'>Mesh FlowPM: distributed, GPU-accelerated, and automatically differentiable simulations</h3>
																																			<!--
																																<img data-src="assets/mesh_flopwm.png" class="plain" style="height:450px;" /> -->

																																			<div class="container">
																																				<div class="col">
																																					<img data-src="assets/mfpm_demo_1024.png" />
																																				</div>

																																				<div class="col">
																																					<ul>
																																						<li> We developed a <b class="alert">Mesh TensorFlow</b> implementation that can scale on GPU clusters (horovod+NCCL).
																																						</li>
																																						<br>
																																						<br>
																																						<li> For a $2048^3$ simulation:
																																							<ul>
																																								<li>Distributed on <b>256</b> NVIDIA V100 GPUs</li>
																																								<li>Runtime: 3 mins</li>
																																							</ul>
																																						</li>
																																						<br>
																																						<br>
																																						<li> Don't hesitate to reach out if you have a use case for model parallelism!<br>
																																							<img data-src="assets/github.png" class="plain" style="height:70px" /><br>

																																							<div> <a href="https://github.com/DifferentiableUniverseInitiative/mesh">https://github.com/DifferentiableUniverseInitiative/mesh</a>
																																							</div>
																																						</li>
																																					</ul>
																																				</div>
																																			</div>
																																		</section>

																																		</section>

																									      						<section>
																									      							<section>
																									      								<h3 class='slide-title'>Example use-case: reconstructing initial conditions by MAP optimization</h3>
																									      								<img data-src="assets/evolvingLSS.jpg" class="plain" /><br>
																									      								<div class="fragment">Going back to simpler times...</div>

																									      								<div class="fragment">
																									      									$$\arg\max_z \ \log p(x_{dm} = f(z)) \ + \ p(z) $$
																									      									where:<br>
																									      									<ul>
																									      										<li> $f$ is <b>FlowPM </b>
																									      										</li>
																									      										<li> $z$ are the initial conditions (early universe)
																									      										</li>
																									      										<li> $x_{dm}$ is the present day dark matter distribution
																									      										</li>
																									      									</ul>
																									      								</div>
																									      							</section>

																									      							<section>
																									      								<h3 class="slide-title"> MAP optimization in action</h3>
																									      								$$\arg\max_z \ \log p(x_{dm} = f(z)) \ + \ p(z) $$
																									      								<div style="float:right; font-size: 16px">credit: <a href="https://github.com/modichirag">C. Modi</a></div>
																									      								<br>
																									      								<div class="container">
																									      									<div class="col fragment fade-up">
																									      										<img data-src="assets/init_field.png" style='height:250px;' />
																									      										<br> True initial conditions <br> $z_0$
																									      									</div>

																									      									<div class="col">
																									      										<img data-src="assets/reconim_init.gif" style='height:250px;' />
																									      										<br> Reconstructed initial conditions $z$
																									      									</div>

																									      									<div class="col">
																									      										<img data-src="assets/reconim_fin.gif" style='height:250px;' />
																									      										<br> Reconstructed dark matter distribution $x = f(z)$
																									      									</div>

																									      									<div class="col">
																									      										<img data-src="assets/fin_field.png" style='height:250px;' />
																									      										<br> Data <br> $x_{DM} = f(z_0)$
																									      									</div>
																									      								</div>
																									      								<br>
																									      								<br>

																									      								<div class="fragment">
																									      									Check out this blogpost for more details <br> <a href=https://blog.tensorflow.org/2020/03/simulating-universe-in-tensorflow.html>
																									      										https://blog.tensorflow.org/2020/03/simulating-universe-in-tensorflow.html</a>
																									      								</div>
																									      							</section>
																									      						</section>



																																					<section>
																																						<h3 class="slide-title">A closer look at the optimization algorithm</h3>

																																						<br>

																																						$$\arg\max_x \ \log p(y | f(x)) \ + \ p(x) $$

																																						<div class="container">
																																							<div class="col">
																																								<ul>
																																									<li> Standard Gradient Descent Algorithm:
																																										$$x_{i+1} = x_i - \epsilon \left[ \nabla_x{\log p(y | f(x_i))} + \nabla_x \log p(x_i) \right]$$
																																										<br>
																																										<div class="fragment" data-fragment-index="2">$$x_{i+1} = x_i - \Gamma \left(\nabla_x{\log p(y | f(x_i))}, \nabla_x \log p(x_i) \right]$$
																																											with <b class="alert">update function</b> $\Gamma: (u,v) \rightarrow \epsilon(u + v)$ </div>
																																									</li>
																																									<br>
																																									<br>
																																									<li class="fragment"> Many algorithms (e.g. ADAM, LBFGS) can expressed in this form with a different choice of $\Gamma$.
																																									</li>
																																								</ul>

																																							</div>
																																							<div class="col fragment" data-fragment-index="1">
																																								<img data-src="assets/map.png" />
																																							</div>
																																						</div>

																																						<br>
																																						<div class="fragment">
																																							$\Longrightarrow$ What if we could learn this update function?
																																						</div>
																																					</section>

																																					<section>
																																						<section>
																																							<h3 class="slide-title">Recurrent Inference Machines for Solving Inverse Problems<br> <a href="https://arxiv.org/abs/1706.04008">Putzky & Welling, 2017</a></h3>

																																							<img data-src="assets/illustration_RIM.png" />

																																							<div class="container">
																																								<div class="col">
																																									<ul>
																																										<li> Introduce a Recurrent Neural Network (RNN) $h_\phi$, and state variable $s$, so that:
																																											$$ s_{i+1} = h^*_\phi( \nabla \log p(y|x_{i}), x_i, s_{i})$$
																																											$$ x_{i+1} = x_i + h_\phi(\nabla \log p(y|x_{i}), x_i, s_{i+1})$$
																																										</li>

																																									</ul>
																																								</div>
																																								<div class="col fragment">
																																									<ul>
																																										<li> Train according to:
																																											$$\mathcal{L} = \sum_{i}^T w_i\mathcal{L}(x_i, x)$$
																																										</li>
																																									</ul>
																																								</div>
																																							</div>
																																						</section>
<!--
																																						<section>
																																							<h3 class="slide-title">Inside an RNN Cell</h3>
																																							<img data-src="assets/LSTM_GRU.png" height="600px" />
																																							(<a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21">source</a>)
																																						</section>

																																						<section>
																																							<h3 class="slide-title">Illustration on inverse problems</h3>
																																							<br>
																																							<br>
																																							<br>
																																							<br>
																																							<div>
																																								<img data-src="assets/IllustrationRIM.png" /><br>
																																								From left to right: input masked image, increasing number of steps of solutions, ground truth.
																																							</div>
																																							<br>
																																							<br>
																																							<br>
																																							<br>
																																						</section> -->
																																					</section>

																																					<section>
																																						<section>
																																							<h3 class="slide-title">CosmicRIM: Recurrence Inference Machines for Initial Condition Reconstruction</h3>
																																							<div class="container">
																																								<div class="col">
																																									<div style="float:right; font-size: 20px"> Modi, <b>Lanusse</b>, Seljak, Spergel, Perreault-Levasseur (2021)
																																										<a href="https://arxiv.org/abs/2104.12864"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2104.12864-B31B1B.svg" class="plain" style="height:25px;vertical-align:middle;" /></a>
																																									</div>
																																								</div>
																																							</div>
																																							<br>

																																							<div class="container">

																																								<div class="col">
																																									Recurrent Neural Network Architecture
																																									<img data-src="assets/cosmic_rim.png" width="450" />
																																								</div>

																																								<div class="col">

																																									<ul>
																																										<li>A few notable differences to a vanilla RIM:
																																											<ul>
																																												<li>We provide gradients of both prior and likelihood to the model.</li>

																																												<br>
																																												<li>Because our forward model couples scales, we use a multiscale U-Net architecture.</li>
																																												<br>
																																												<li> Input gradients are pre-scaled with the ADAM formula.</li>
																																											</ul>
																																										</li>

																																									</ul>

																																								</div>
																																							</div>
																																							<br>
																																						</section>

																																						<section>
																																							<h3 class="slide-title">Experiments</h3>
																																							<div class="block ">
																																								<div class="block-title">
																																									Settings
																																								</div>
																																								<div class="block-content">
																																									<ul>
																																										<li>Forward model: $64^3$ particles, 400 Mpc/h box, 2LPT dynamics with 2nd order bias model
																																										</li>
																																										<li> RIM: 10 steps, trained under l2 loss
																																										</li>
																																									</ul>
																																								</div>
																																							</div>

																																							<div class="container">

																																								<div class="col">
																																									Initial conditions cross-correlation
																																									<img data-src="assets/cosmic_rim_rc.png" width="500" />

																																								</div>
																																								<div class="col">
																																									Transfer function<br>
																																									<img data-src="assets/rim_transfer.png" width="500" />
																																								</div>

																																							</div>
																																							<ul>
																																								<li>CosmicRIM: Learn to optimize by embedding a Neural Network in the optimization algorithm.<br>
																																									$\Longrightarrow$ converges 40x faster than LBFGS.</li>
																																							</ul>

																																						</section>
																																					</section>


		<section>
			<h1> Conclusion </h1>
		</section>

		<section>
			<h3 class="slide-title"> Conclusion </h3>
			<div class="block ">
				<div class="block-title">
					Merging Deep Learning and Physical Models
				</div>
				<div class="block-content">
					<br>
					<ul>
						<li class="fragment"> <b>Complement known physical models with data-driven components</b>
							<ul>
								<li>Learn galaxy morphologies from noisy and PSF-convolved data, for simulation purposes.</li>
								<li>Use data-driven model as prior for solving inverse problems such as deblending or deconvolution.</li>
							</ul>
						</li>
						<br>
						<li class="fragment"> <b>Leverage simulators as physical models</b> for parameter inference
							<ul>
								<li> Lifts the restrictions of analytic summary statistics (like 2pt functions)
								</li>
								<li> Provides full automated inference methodology that only requires a simulator
								</li>
							</ul>
						</li>
						<br>
						<li class="fragment"> <b>Automatically differentiable physical models</b>
							<ul>
								<li> Allows for fast inference in high dimensions.</li>
								<li> Can be interfaced with neural networks in plenty of exciting ways.</li>
							</ul>
						</li>
						<br>
					</ul>
				</div>
			</div>
			<br>

			<div class="fragment">
			<b>Free advertisement:</b><br><br>
			<ul>
				<li class="fragment"> <a href="https://ml4astro.github.io/icml2022/">ICML 2022 Workshop on Machine Learning for Astrophysics</a>, extended abstract submission deadline May 23rd.
					<br> $\Longrightarrow$ The theme is <b>how to make machine learning useful for science</b>.
				</li>
			</ul>
		</div>
			<br>
			<p class="fragment">Thank you ! </p>
			<br> <br> <br>
		</section>


		</div>
	</div>

	<style>
		/* .reveal .slides {
			border: 5px solid red;
			min-height: 100%;
			width: 128mm;
			height: 96mm;
		} */

		.reveal .block {
			background-color: #191919;
			margin-left: 20px;
			margin-right: 20px;
			text-align: left;
			padding-bottom: 0.1em;
		}

		.reveal .block-title {
			background-color: #333333;
			padding: 8px 35px 8px 14px;
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .block-content {
			padding: 8px 35px 8px 14px;
		}

		.reveal .slide-title {
			border-left: 5px solid white;
			text-align: left;
			margin-left: 20px;
			padding-left: 20px;
		}

		.reveal .alert {
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .inverted {
			filter: invert(100%);
		}

		/*
	/* .reveal .alert {
	padding:8px 35px 8px 14px; margin-bottom:18px;
	text-shadow:0 1px 0 rgba(255,255,255,1);
	border:5px solid #FFAA7F;
	-webkit-border-radius: 14px; -moz-border-radius: 14px;
	border-radius:14px
	background-position: 10px 10px;
	background-repeat: no-repeat;
	background-size: 38px;
	padding-left: 30px; /* 55px; if icon
	}
	.reveal .alert-block {padding-top:14px; padding-bottom:14px}
	.reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
	/*.reveal .alert li {margin-top: 1em}
	.reveal .alert-block p+p {margin-top:5px} */
	</style>


	<script src="reveal.js/dist/reveal.js"></script>
	<script src="reveal.js/plugin/notes/notes.js"></script>
	<script src="reveal.js/plugin/markdown/markdown.js"></script>
	<script src="reveal.js/plugin/highlight/highlight.js"></script>
	<script src="reveal.js/plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			controls: true,

			//center: false,
			hash: true,

			// Visibility rule for backwards navigation arrows; "faded", "hidden"
			// or "visible"
			controlsBackArrows: 'hidden',

			// Display a presentation progress bar
			progress: true,

			// Display the page number of the current slide
			slideNumber: true,

			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// The "normal" size of the presentation, aspect ratio will be preserved
			// when the presentation is scaled to fit different resolutions. Can be
			// specified using percentage units.
			width: 1280,
			height: 720,

			// Factor of the display size that should remain empty around the content
			margin: 0.1,

			// Bounds for smallest/largest possible scale to apply to content
			minScale: 0.2,
			maxScale: 1.5,

			autoPlayMedia: true,

			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath],

			dependencies: [{
					src: 'reveal.js/plugin/markdown/marked.js'
				},
				{
					src: 'reveal.js/plugin/markdown/markdown.js'
				},
				{
					src: 'reveal.js/plugin/notes/notes.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/math/math.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/reveal.js-d3/reveald3.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js'
				},
				{
					src: 'reveal.js/plugin/highlight/highlight.js',
					async: true
				},
			]

		});
	</script>
</body>

</html>
